{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7aed799",
   "metadata": {},
   "source": [
    "# Imports and Usefull Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d76a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load feature and target data\n",
    "def loadDataset(dataSetDir = './SecondDataSets/TrainingDataSets/gosplData.npz'):\n",
    "    dataSet = np.load(dataSetDir)\n",
    "    features = dataSet['features']\n",
    "    targets = dataSet['targets']\n",
    "    return features, targets\n",
    "\n",
    "#Coordinate transformation from cartesian to polar\n",
    "def cartesianToPolarCoords(XYZ, useLonLat=True):\n",
    "    X, Y, Z = XYZ[:, 0], XYZ[:, 1], XYZ[:, 2]\n",
    "    R = (X**2 + Y**2 + Z**2)**0.5\n",
    "    theta = np.arctan2(Y, X)\n",
    "    phi = np.arccos(Z / R)\n",
    "\n",
    "    # Return results either in spherical polar or leave it in radians\n",
    "    if useLonLat == True:\n",
    "        theta, phi = np.degrees(theta), np.degrees(phi)\n",
    "        lon, lat = theta - 180, 90 - phi\n",
    "        lon[lon < -180] = lon[lon < -180] + 360\n",
    "        return R, lon, lat\n",
    "    else:\n",
    "        return R, theta, phi\n",
    "\n",
    "#Coordinate transformation from spherical polar to cartesian\n",
    "def polarToCartesian(radius, theta, phi, useLonLat=True):\n",
    "    if useLonLat == True:\n",
    "        theta, phi = np.radians(theta+180.), np.radians(90. - phi)\n",
    "    X = radius * np.cos(theta) * np.sin(phi)\n",
    "    Y = radius * np.sin(theta) * np.sin(phi)\n",
    "    Z = radius * np.cos(phi)\n",
    "\n",
    "    # Return data either as a list of XYZ coordinates or as a single XYZ coordinate\n",
    "    if (type(X) == np.ndarray):\n",
    "        return np.stack((X, Y, Z), axis=1)\n",
    "    else:\n",
    "        return np.array([X, Y, Z])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696283b5",
   "metadata": {},
   "source": [
    "# Visualizing the Training Data\n",
    "\n",
    "Before we continue, we visualize the data to make sure that they are in the correct format and haven't been corrupted along the way. These functions will also be usefull to visualize the output of the tensorflow models later on.\n",
    "\n",
    "In the code bellow, we provide a visualization of the data in the image format. This format is more representative of how tensorflow will actually see the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab052b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image representation of a sample image\n",
    "def visualizeAsImages(featureImage, targetImage):\n",
    "    featureImage -= np.min(featureImage, axis=(0, 1))\n",
    "    featureImage /= np.max(featureImage, axis=(0, 1))\n",
    "    targetImage -= np.min(targetImage, axis=(0, 1))\n",
    "    targetImage /= np.max(targetImage, axis=(0, 1))\n",
    "    targetImage[:, :, 2] **= 0.125\n",
    "\n",
    "    #Set up plotting figure\n",
    "    fig, axis = plt.subplots(1, 3)\n",
    "    fig.set_figheight(12)\n",
    "    fig.set_figwidth(18)\n",
    "    axis[0].imshow(featureImage[:, :, 0])\n",
    "    axis[1].imshow(featureImage[:, :, 1])\n",
    "    axis[2].imshow(targetImage)\n",
    "    axis[0].set_title('Initial Elevations')\n",
    "    axis[1].set_title('Tectonic Uplift')\n",
    "    axis[2].set_title('Combined Output Data')\n",
    "    axis[0].set_xticks([])\n",
    "    axis[0].set_yticks([])\n",
    "    axis[1].set_xticks([])\n",
    "    axis[1].set_yticks([])\n",
    "    axis[2].set_xticks([])\n",
    "    axis[2].set_yticks([])\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "\n",
    "# Load dataset and visualize a sample from it\n",
    "features, targets = loadDataset()\n",
    "visualizeAsImages(features[0], targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3226d69",
   "metadata": {},
   "source": [
    "Although the data used will be in an image format, it is meant to represent a spherical planet. The code bellow provides a spherical representation of what the data looks like, with an exagerated terrain based on the final elevations. This function will also be compatible with the outputs of the tensorflow models.\n",
    "\n",
    "In the top left corner of the ITK plotter window, there is a dropdown meny represented by 3 lines. Within this dropdown menu, we can chose which parameter to color code the mesh with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926cf068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pyvista mesh object with exagerated terrains and data attached to it\n",
    "def createExageratedMesh(featureSample, targetSample, amplificationFactor=90, earthRadius=6378137):\n",
    "    \n",
    "    # Reshape sample data and re-insert placeholder values (zeros) for north and south poles\n",
    "    imageDims = np.array(features.shape[1:3])\n",
    "    featureSample = featureSample.reshape(imageDims[0] * imageDims[1], 2)\n",
    "    featureSample = np.insert(featureSample, 0, 0, axis=0)\n",
    "    featureSample = np.insert(featureSample, 0, 0, axis=0)\n",
    "    targetSample = targetSample.reshape(imageDims[0] * imageDims[1], 3)\n",
    "    targetSample = np.insert(targetSample, 0, 0, axis=0)\n",
    "    targetSample = np.insert(targetSample, 0, 0, axis=0)\n",
    "\n",
    "    # Create a planet mesh with exagerated final elevations\n",
    "    uvSphere = pv.Sphere(theta_resolution=imageDims[0], phi_resolution=imageDims[1]+2)\n",
    "    r, lon, lat = cartesianToPolarCoords(uvSphere.points)\n",
    "    exegeratedRadius = earthRadius + amplificationFactor * targetSample[:, 0]\n",
    "    exageratedXYZ = polarToCartesian(exegeratedRadius, lon, lat)\n",
    "    exageratedMesh = pv.PolyData(exageratedXYZ.T, uvSphere.faces)\n",
    "\n",
    "    # Attach data to the exagerated mesh\n",
    "    exageratedMesh['Initial Elevations'] = featureSample[:, 0]\n",
    "    exageratedMesh['Tectonic Uplift'] = featureSample[:, 1]\n",
    "    exageratedMesh['Final Elevations'] = targetSample[:, 0]\n",
    "    exageratedMesh['Erosion Deposition'] = targetSample[:, 1]\n",
    "    exageratedMesh['Flow Accumilation'] = targetSample[:, 2]**0.125\n",
    "    return exageratedMesh\n",
    "\n",
    "# Load data and create mesh\n",
    "sampleNumber = 10\n",
    "features, targets = loadDataset()\n",
    "exageratedMesh = createExageratedMesh(features[sampleNumber], targets[sampleNumber])\n",
    "\n",
    "# Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(exageratedMesh, scalars='Final Elevations')\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee5d56",
   "metadata": {},
   "source": [
    "# Sigmoids and Logit Functions\n",
    "\n",
    "Machine learning models generally don't perform well when the training data is within some random range, instead we want all data to be within a range of $[-1, 1]$, or sometimes within $[0, 1]$. We also don't want to use the standard normalization technique, because this would artificially introduce a lower and upper bound on our data.\n",
    "\n",
    "We can use the sigmoid function to bring the data into the range of $[0, 1]$, and a logit function to bring it back to the original data domain. We refer to *gain* as the steepness of the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23aaa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to bring data to 0-1\n",
    "def sigmoid(x, gain=1):\n",
    "    return 1 / (1 + np.exp(- gain * x))\n",
    "\n",
    "# Inverse function to bring data back to original domain\n",
    "def logit(x, gain=1):\n",
    "    return np.log(x / (1 - x)) / gain\n",
    "\n",
    "# Create XY data to demonstrate functions with\n",
    "x = np.arange(-10, 10, 0.01)\n",
    "y = sigmoid(x, gain=1)\n",
    "a = np.arange(0.01, 0.99, 0.01)\n",
    "b = logit(a, gain=1)\n",
    "\n",
    "# Plot functions\n",
    "fig, axis = plt.subplots(1, 2)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(16)\n",
    "axis[0].plot(x, y)\n",
    "axis[1].plot(a, b)\n",
    "axis[0].set_title('Sigmoid')\n",
    "axis[1].set_title('Logit')\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fdc121",
   "metadata": {},
   "source": [
    "When using the above functions, we want to choose an appropriate gain for each variable to avoid all values being too close to 0 or 1, but rather something inbetween. Otherwise the neural network may not *see* the relevant details of our data set.\n",
    "\n",
    "We can use the figures bellow to figure out what range our data typically lies within, and decide what gain is suitable for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940cbd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, targets = loadDataset()\n",
    "feats = features[0:5].reshape(5 * 512 * 256, 2)\n",
    "targs = targets[0:5].reshape(5 * 512 * 256, 3)\n",
    "\n",
    "fig, axis = plt.subplots(5, 1)\n",
    "fig.set_figheight(12)\n",
    "fig.set_figwidth(16)\n",
    "axis[0].plot(feats[:, 0], linewidth=0.05)\n",
    "axis[1].plot(feats[:, 1], linewidth=0.05)\n",
    "axis[2].plot(targs[:, 0], linewidth=0.05)\n",
    "axis[3].plot(targs[:, 1], linewidth=0.05)\n",
    "axis[4].plot(targs[:, 2]**0.125, linewidth=0.05)\n",
    "for i in range(5):\n",
    "    axis[i].set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae4722a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9fa88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e5d876e",
   "metadata": {},
   "source": [
    "# The Unet Model\n",
    "\n",
    "As discussed in our previous notebooks, the Unet model seems to be the most promising neural network architecture for our goal. We will explore the effectiveness of the Unet model when trained with a simple loss function and when trained in the context of a GAN.\n",
    "\n",
    "The code bellow is taken and modified from [*nanoxas/sketch-to-terrain* Github](https://github.com/nanoxas/sketch-to-terrain/blob/master/model.py), where [Eric Guerin et. al.](https://hal.archives-ouvertes.fr/hal-01583706/file/tog.pdf) had a similar goal in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we define the structure of the generator Unet model\n",
    "def getUnet(imageDims):\n",
    "    imageWidth, imageHeight = imageDims[1], imageDims[0]\n",
    "    \n",
    "    #Input layer\n",
    "    inputs = layers.Input((imageHeight, imageWidth, 2))\n",
    "    \n",
    "    #A few convolutional layers with maxpooling\n",
    "    #This is the encoder part of the model that interprets the input image\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    #Their last convolution layer in their encoder seems to have skip layer with noise introduced to it\n",
    "    #Noise is often used to avoid the overfiting of a machine learning model\n",
    "    noise = layers.Input((K.int_shape(conv5)[1], K.int_shape(conv5)[2], K.int_shape(conv5)[3]))\n",
    "    conv5 = layers.Concatenate()([conv5, noise])\n",
    "    \n",
    "    #From my understanding, upsampling is used to increase the weight of data in the minority class\n",
    "    #Skip layer (connects conv4 layer directly to up6 layer), and more convolutional layers\n",
    "    up6 = layers.Conv2D(512, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv5))\n",
    "    merge6 = layers.Concatenate()([conv4, up6])\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    up7 = layers.Conv2D(256, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = layers.Concatenate()([conv3, up7])\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "    \n",
    "    up8 = layers.Conv2D(128, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = layers.Concatenate()([conv2, up8])\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "    \n",
    "    up9 = layers.Conv2D(64, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = layers.Concatenate()([conv1, up9])\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "    conv9 = layers.Conv2D(32, 3, activation='relu', padding='same')(conv9)\n",
    "    conv10 = layers.Conv2D(3, 1, activation='tanh')(conv9)\n",
    "    \n",
    "    #Create and return the final model\n",
    "    model = Model(inputs=[inputs, noise], outputs=conv10)\n",
    "    return model\n",
    "\n",
    "\n",
    "features, targets = loadDataset()\n",
    "imageDims = features.shape[1:3]\n",
    "generator = getUnet(imageDims)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 2\n",
    "featuresBatch = features[0:batchSize]\n",
    "noise = np.random.normal(0, 1, (batchSize, 32, 16, 1024))\n",
    "generatedImageBatch = generator([featuresBatch, noise], training=False).numpy()\n",
    "\n",
    "#print(generatedImageBatch)\n",
    "print(np.min(generatedImageBatch))\n",
    "print(np.max(generatedImageBatch))\n",
    "\n",
    "visualizeAsImages(featuresBatch[0], generatedImageBatch[0])\n",
    "\n",
    "'''\n",
    "exageratedMesh = createExageratedMesh(featuresBatch[0], generatedImageBatch[0])\n",
    "\n",
    "# Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(exageratedMesh, scalars='Final Elevations')\n",
    "plotter.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ed038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dcdd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17299a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293e810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c46dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171f633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
