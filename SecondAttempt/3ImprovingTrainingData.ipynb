{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46db299",
   "metadata": {},
   "source": [
    "In the previous notebook, we explored various tensorflow models and found that the U-net model was the most capable neural network for simulating erosion. Although the model is able to generate results that somewhat resembles the training target data, it did not manage to replicate the fine details of the errosion simulations. The changes of the landscape due to erosion are very subtle and so it is difficult to learn.\n",
    "\n",
    "We could further improve the model and get it to learn the more subtle details, but for now it is easier to simply generate data with more dramatic landscape changes.\n",
    "\n",
    "# Running this Notebook\n",
    "\n",
    "To run this notebook, I reccomend using [this docker environment for GOSPL](https://hub.docker.com/r/geodels/gospl). The main libraries needed here are GOSPL and Pyvista. In the next notebook, we will not be using GOSPL, but tensorflow instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f663c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import stripy\n",
    "import meshplex\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import matplotlib.pyplot as plt\n",
    "from gospl.model import Model as sim\n",
    "from gospl._fortran import definegtin\n",
    "from TrainingDataGenerator import DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a13f1",
   "metadata": {},
   "source": [
    "# Data Generator\n",
    "\n",
    "To simplify the code, I created the *TrainingDataGenerator.py* script that handles GOSPL simulations using an object oriented approach. This helps us avoid having to pass and keep track of the many parameters involved. Most of the code and algorithms used by the data generator are already described in the first notebook of the first attempt of this project. You can read the first notebook to understand the theory in more detail. In addition to the previous code, the data generator also handles tectonic uplift forces for the GOSPL simulation.\n",
    "\n",
    "Bellow we demonstrate how we can specify various simulation parameters. Note that these are all optional input parameters, and we can initiate the data generator without specifying any of these, in this case the data generator will simply use their default settings.\n",
    "\n",
    "We also provide a visualization of the initial topography (elevations) and the tectonic uplift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4de0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise parameters for initial topography and tectonic uplift\n",
    "topographyNoiseParameters = {\n",
    "    \"octaves\" : 8,\n",
    "    \"octaveStepSize\" : 1.4,\n",
    "    \"amplitudeStepSize\" : 2.0,\n",
    "    \"initialFrequency\" : 0.000001,\n",
    "    \"noiseMinMax\" : np.array([-4000, 1000])}\n",
    "upliftNoiseParameters = {\n",
    "    \"octaves\" : 6,\n",
    "    \"octaveStepSize\" : 1.4,\n",
    "    \"amplitudeStepSize\" : 2.4,\n",
    "    \"initialFrequency\" : 0.0000002,\n",
    "    \"noiseMinMax\" : np.array([0, 2000])}\n",
    "\n",
    "# We initialise the data generator with desired parameters\n",
    "datGen = DataGenerator(\n",
    "    \n",
    "                # Mesh and simulation parameters\n",
    "                subdivisions = 6, #Subdivisions for the icosphere\n",
    "                radius = 6378137, #Earths radius in meters\n",
    "                \n",
    "                # Time related parameters\n",
    "                startTime = 0, #Simulation start time in years\n",
    "                endTime = 60000000, #Simulation end time in years\n",
    "                tOut = 1000000, #Write data files at every tOut number of years\n",
    "                deltaTime = 100000, #Time steps for the simulation\n",
    "                tecTime = 1000000,\n",
    "                \n",
    "                # Noise parameters for initial topography and tectonic uplift\n",
    "                topographyNoiseParameters = topographyNoiseParameters,\n",
    "                upliftNoiseParameters = upliftNoiseParameters,\n",
    "                \n",
    "                # Main directory to store results in\n",
    "                dataDir = './SecondDataSets/GosplTrials'\n",
    ")\n",
    "\n",
    "# Visualize initial elevations and tectonic uplift\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(datGen.icoMesh, scalars='elevations')\n",
    "#plotter.add_mesh(datGen.icoMesh, scalars='uplift')\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c8224",
   "metadata": {},
   "source": [
    "We can then run a gospl simulation trial as follows. Within the main results data directory, the data generator will create a subdirectory name *Trial{}* followed by some number. The number is chosen based on how many trials data is already present in the main results directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89890b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to true to actually run the trial\n",
    "if False:\n",
    "    datGen.prepareAndRunGOSPLtrial()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38567cf",
   "metadata": {},
   "source": [
    "# Generating Lots of Data\n",
    "\n",
    "We can also automatically run many GOSPL simulation trials using the code bellow. For the purpose of training a neural network, we will need data generated from hundreds of trials, so we can simply let the code bellow run over long periods of time until the user interupts by restarting the jupyter notebook kernel.\n",
    "\n",
    "After interupting the code bellow, the latest running trial will probably be incomplete, so make sure to delete the latest trial subdirectory.\n",
    "\n",
    "In the future, we could randomise some of the GOSPL simulation parameters, and implement the paramters as inputs of the neural network. Hoever, to do so we will require significantly more training examples, and it will complicate things further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14782ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endTime = 60000000\n",
    "deltaTime = 100000\n",
    "dataDir = './SecondDataSets/TrialsWithSubdivision6'\n",
    "\n",
    "# Run many GOSPL trials until user interupts\n",
    "while False:\n",
    "    datGen = DataGenerator(\n",
    "        dataDir = dataDir,\n",
    "        endTime = endTime,\n",
    "        deltaTime = deltaTime)\n",
    "    datGen.prepareAndRunGOSPLtrial()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab846c",
   "metadata": {},
   "source": [
    "# Visualizing Results Data\n",
    "\n",
    "After running some GOSPL simulations, we can visualize the results as follows. This will create an mesh of the results with exagerated elevations. \n",
    "\n",
    "Note that to properly load simulation trial, we need to make sure that we initiate the *DataGenerator* with the some of the same parameters that were used to run the simulation itself. The *subdivisions* parameter and any directory related parameters will all need to be the same.\n",
    "\n",
    "In the top left corner of the ITK plotter window, there is a dropdown meny represented by 3 lines. Within this dropdown menu, we can chose which results parameter to color code the mesh with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialNumber = 33\n",
    "iterationToPlot = 60\n",
    "amplificationFactor = 90\n",
    "dataDir = './Data/TrialsWithSubdivision6'\n",
    "\n",
    "# Load trial and animate results\n",
    "datGen = DataGenerator(dataDir=dataDir,\n",
    "                      amplificationFactor=amplificationFactor)\n",
    "datGen.loadTrial(trialNumber)\n",
    "\n",
    "# Create mesh from results data with exagerated elevations\n",
    "gosplDict = datGen.readGosplFile(iterationToPlot)\n",
    "mesh = datGen.createExageratedMesh(gosplDict)\n",
    "\n",
    "# Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(mesh, scalars='elev')\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a98c19",
   "metadata": {},
   "source": [
    "Alternatively, we can also create an animations of the results as follows. By default, this animation will be saved as an MP4 file in the same directory of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c69cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialNumber = 33\n",
    "endTime = 60000000\n",
    "numberOfIterations = 60\n",
    "amplificationFactor = 120\n",
    "animationDir = 'ErosionAnimation.mp4'\n",
    "dataDir = './Data/TrialsWithSubdivision6'\n",
    "\n",
    "# Load trial and animate results\n",
    "datGen = DataGenerator(dataDir=dataDir,\n",
    "                      animationDir=animationDir,\n",
    "                      endTime=endTime,\n",
    "                      amplificationFactor=amplificationFactor)\n",
    "datGen.loadTrial(trialNumber)\n",
    "datGen.animateGosplResults(iterations=numberOfIterations, scalarToPlot='elev')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c15877",
   "metadata": {},
   "source": [
    "# Processing Data for Tensorflow\n",
    "\n",
    "For now, we plan on training a convolutional neural network, which requires our data to be in an array shaped similar to those of images, however GOSPL requires the data to be on an Icosphere. By interpolating our data onto a UV sphere, we can treat the longitudinal and latitudinal coordinates like the X and Y axis of image data, and thus bring the data into the required format.\n",
    "\n",
    "In the future, we could potentially avoid this by using mesh based neural networks, however this will complicate things for now and the tools/literature are no where near as well established."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a994b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialNumber = 0\n",
    "finalIteration = 60\n",
    "uvSphereResolution = [512, 258]\n",
    "dataDir = './Data/TrialsWithSubdivision6'\n",
    "scalarsToInterpolate = ['elev', 'erodep', 'flowAcc']\n",
    "\n",
    "# Initiate data generator and load trial\n",
    "datGen = DataGenerator(dataDir = dataDir, \n",
    "                       uvSphereResolution = uvSphereResolution,\n",
    "                       scalarsToInterpolate = scalarsToInterpolate)\n",
    "datGen.loadTrial(trialNumber)\n",
    "\n",
    "# Interpolate data onto UV sphere\n",
    "inputData = datGen.interpolateInputDataToUVsphere(finalIteration=finalIteration)\n",
    "outputData = datGen.interpolateGosplDataToUVsphere(finalIteration=finalIteration)\n",
    "\n",
    "# Add interpolated data to uvSphere mesh (for visualization)\n",
    "uvSphere = datGen.uvSphere\n",
    "uvSphere['initialElevations'] = inputData[0]\n",
    "uvSphere['tectonicUplift'] = inputData[1]\n",
    "uvSphere['finalElevations'] = outputData[0]\n",
    "uvSphere['erosionDeposition'] = outputData[1]\n",
    "uvSphere['flowAccumulation'] = outputData[2]**0.125\n",
    "\n",
    "# Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(uvSphere, scalars='finalElevations')\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50026da6",
   "metadata": {},
   "source": [
    "In the code bellow, we demonstrate how the data would look like in an image format. In doing so, we need to remove data on vertices corresponding to the north and south poles of the planet, because we otherwise can not reshape the arrays into the desired formats. This is a more accurate representation of how tensorflow will actually receive its training data, and what it is trying to learn.\n",
    "\n",
    "In the image corresponding to the output data:\n",
    "- Red represents the final elevations\n",
    "- Green represents the erosion deposition\n",
    "- Blue represents the flow accumulation\n",
    "\n",
    "Note that we normalize and adjust the data to make features more visible, but these modifications are not required for them to be compatible with tensorflow. We might however, pass the data through a sigmoid function to bring them into a range of $[0, 1]$, without strictly imposing a height limit on elevations and other parameters. We could also include additional output parameters for the neural network to learn, which could potentially improve the model, as it has more data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4bbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialNumber = 1\n",
    "finalIteration = 60\n",
    "uvSphereResolution = [512, 258]\n",
    "dataDir = './Data/TrialsWithSubdivision6'\n",
    "scalarsToInterpolate = ['elev', 'erodep', 'flowAcc']\n",
    "\n",
    "# Initiate data generator and load trial\n",
    "datGen = DataGenerator(dataDir = dataDir, \n",
    "                       uvSphereResolution = uvSphereResolution,\n",
    "                       scalarsToInterpolate = scalarsToInterpolate)\n",
    "datGen.loadTrial(trialNumber)\n",
    "\n",
    "# Interpolate input data onto UV sphere and normalize just for the purpose of visualization\n",
    "inputDat = datGen.interpolateInputDataToUVsphere(finalIteration=finalIteration)\n",
    "inputDat = inputDat.T[2:]\n",
    "inputDat -= np.min(inputDat, axis=0)\n",
    "inputDat /= np.max(inputDat, axis=0)\n",
    "inputDat = inputDat.reshape(uvSphereResolution[0], uvSphereResolution[1]-2, 2)\n",
    "\n",
    "# Interpolate output data onto UV sphere and normalize just for the purpose of visualization\n",
    "outputData = datGen.interpolateGosplDataToUVsphere(finalIteration=finalIteration)\n",
    "outputData[2] **= 0.125\n",
    "outputData = outputData.T[2:]\n",
    "outputData -= np.min(outputData, axis=0)\n",
    "outputData /= np.max(outputData, axis=0)\n",
    "outputData = outputData.reshape(uvSphereResolution[0], uvSphereResolution[1]-2, 3)\n",
    "\n",
    "#Set up plotting figure\n",
    "fig, axis = plt.subplots(1, 3)\n",
    "fig.set_figheight(12)\n",
    "fig.set_figwidth(18)\n",
    "axis[0].imshow(inputDat[:, :, 0])\n",
    "axis[1].imshow(inputDat[:, :, 1])\n",
    "axis[2].imshow(outputData)\n",
    "axis[0].set_title('Initial Elevations')\n",
    "axis[1].set_title('Tectonic Uplift')\n",
    "axis[2].set_title('Combined Output Data')\n",
    "axis[0].set_xticks([])\n",
    "axis[0].set_yticks([])\n",
    "axis[1].set_xticks([])\n",
    "axis[1].set_yticks([])\n",
    "axis[2].set_xticks([])\n",
    "axis[2].set_yticks([])\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0549e9",
   "metadata": {},
   "source": [
    "Now that we have shown how the final data set will be represented, all that is left to do is to iterate over all GOSPL trial directories, pre-process the data and save them all into a single NPZ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTrialNumber = 4 #224\n",
    "finalIteration = 60\n",
    "uvSphereResolution = [512, 258]\n",
    "dataDir = './Data/TrialsWithSubdivision6'\n",
    "scalarsToInterpolate = ['elev', 'erodep', 'flowAcc']\n",
    "outputTrainingDatasetDir = './Data/TrainingDataSets/gosplData.npz'\n",
    "\n",
    "featureDataset = []\n",
    "targetDataset = []\n",
    "\n",
    "# Iterate over all trials and process data for tensorflow\n",
    "for trialNumber in range(maxTrialNumber+1):\n",
    "    datGen = DataGenerator(dataDir = dataDir, \n",
    "                           uvSphereResolution = uvSphereResolution,\n",
    "                           scalarsToInterpolate = scalarsToInterpolate)\n",
    "    datGen.loadTrial(trialNumber)\n",
    "\n",
    "    # Interpolate input data onto UV sphere and normalize just for the purpose of visualization\n",
    "    inputDat = datGen.interpolateInputDataToUVsphere(finalIteration=finalIteration)\n",
    "    inputDat = inputDat.T[2:]\n",
    "    inputDat = inputDat.reshape(uvSphereResolution[0], uvSphereResolution[1]-2, 2)\n",
    "    featureDataset.append(inputDat)\n",
    "\n",
    "    # Interpolate output data onto UV sphere and normalize just for the purpose of visualization\n",
    "    outputData = datGen.interpolateGosplDataToUVsphere(finalIteration=finalIteration)\n",
    "    outputData = outputData.T[2:]\n",
    "    outputData = outputData.reshape(uvSphereResolution[0], uvSphereResolution[1]-2, 3)\n",
    "    targetDataset.append(outputData)\n",
    "\n",
    "# Save all processed data as an NPZ file\n",
    "featureDataset = np.array(featureDataset)\n",
    "targetDataset = np.array(targetDataset)\n",
    "#np.savez(outputTrainingDatasetDir, features=featureDataset, targets=targetDataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
