{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be310a6",
   "metadata": {},
   "source": [
    "# Aim\n",
    "\n",
    "In this project, we would like to train a Generative Adversarial Network (GAN) to simulate dynamic earth processes from data generated by GOSPL. To do so, we will first need to generate a lot of data that our GAN can learn from. In this notebook, we will use noise based \n",
    "\n",
    "In this notebook, we will use noise based method to procedurally create input data for GOSPL and run the GOSPL simulations. The input and output data of the GOSPL simulations will be used to train the GAN, and hopefully the GAN will be able to simulate the same results, but much faster.\n",
    "\n",
    "Note that for now, we will keep things as simple as possible, and build up from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c39a6a",
   "metadata": {},
   "source": [
    "# Noise\n",
    "\n",
    "To randomly generate input data for GOSPL, we will need to generate random noise. We will be taking advantage of the pyvista perlin noise function as our base source of noise. Note that the *pv.perlin_noise* function is very new to pyvista and so we must use the latest version of pyvista to take advantage of it.\n",
    "\n",
    "The perlin noise function always returns the exact same values if the input is the same, making it not random. To make it pseudo random, we will pass it a random phase offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9479fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import stripy\n",
    "import meshplex\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from gospl.model import Model as sim\n",
    "from gospl._fortran import definegtin\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3ef1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ebfc4323ed403488edc4edf3977ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ebfc4323ed403488edc4edf3977ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Given a list of XYZ coordinates, we sample a noise value at each point\n",
    "def samplePerlinNoise(XYZ, amplitude=1, frequency=4, offset=None):\n",
    "    if offset == None: #Random offset if none other is specified\n",
    "        offset = np.random.rand(3) * 100000\n",
    "    freq = (frequency, frequency, frequency)\n",
    "    noise = pv.perlin_noise(amplitude, freq, offset)\n",
    "    return np.array([noise.EvaluateFunction(xyz) for xyz in XYZ])\n",
    "    \n",
    "#Create a plane, sample noise and apply noise to heights of points on plane\n",
    "plane = pv.Plane(i_size=10, j_size=10, i_resolution=400, j_resolution=400)\n",
    "noiseSamples = samplePerlinNoise(plane.points)\n",
    "plane.points[:, 2] += noiseSamples * 0.1\n",
    "\n",
    "#Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(plane, scalars=noiseSamples)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ae9d9",
   "metadata": {},
   "source": [
    "The above noise function only has a single frequency within it, and therefore looks a bit too artificial. To make the noise look more natural, we will sum up multiple noise samples, each with their own frequency and amplitude. We refer to each noise sample as an octave of the final noise. Given a specified initial frequency, each octave will have a frequency of:\n",
    "\n",
    "$$ f_{oct} = f_{init}  s_o ^ i$$\n",
    "\n",
    "where $s_o$ is the octave step size and $i$ is the current number of the current octave. Each noise sample will have a decreasing amplitude based on the amplitude step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46fc701b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6442118651453982759da5ed17382f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6442118651453982759da5ed17382f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sample noise with multiple noise frequencies\n",
    "def sampleNoise(XYZ, initialFrequency=1, octaves=8, octaveStepSize=1.4, amplitudeStepSize=2):\n",
    "    noiseSum = np.zeros(XYZ.shape[0])\n",
    "    for i in range(octaves):\n",
    "        frequency =  initialFrequency * octaveStepSize ** i\n",
    "        noiseSum += samplePerlinNoise(XYZ, frequency=frequency) / (amplitudeStepSize*(i+1))\n",
    "    return noiseSum\n",
    "\n",
    "#Create a plane, sample noise and apply noise to heights of points on plane\n",
    "plane = pv.Plane(i_size=10, j_size=10, i_resolution=400, j_resolution=400)\n",
    "noiseSamples = sampleNoise(plane.points)\n",
    "plane.points[:, 2] += noiseSamples * 0.4\n",
    "\n",
    "#Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(plane, scalars=noiseSamples)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128c137",
   "metadata": {},
   "source": [
    "# Spheres\n",
    "\n",
    "Although pyvista does have a built in function for creating spheres, it returns a UV sphere. Since GOSPL requires an Icosphere, we will generate one from the *stripy* library and convert it to a pyvista object instead. In the code bellow, we generate an Icosphere and convert it to a pyvista object. We then plot the Icosphere in blue, and a UV sphere in red for comparisons. Notice how the layout of vertices and edges are different.\n",
    "\n",
    "Since we will be needing the cell array generated by stripy later on, we can store this array within the pyvista mesh object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10081f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76bc8ecdcc04542bbb400d0431c7734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76bc8ecdcc04542bbb400d0431c7734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a pyvista icosphere from stripy library (since pyvista doesn't have an Icosphere)\n",
    "def createIcosphere(subdivisions=6, radius=6378137):\n",
    "    icosphere = stripy.spherical_meshes.icosahedral_mesh( \n",
    "                    refinement_levels = subdivisions,\n",
    "                    include_face_points = False)\n",
    "    icosphereXYZ = icosphere._points * radius\n",
    "    icoFaces = stripyCellsToPyvistaFaces(icosphere.simplices)\n",
    "    icoMesh = pv.PolyData(icosphereXYZ, icoFaces)\n",
    "    icoMesh['cells'] = icosphere.simplices\n",
    "    return icoMesh\n",
    "\n",
    "#Create an array for the pyvista faces based on stripy cells\n",
    "def stripyCellsToPyvistaFaces(cells):\n",
    "    faces = []\n",
    "    for cell in cells:\n",
    "        faces.append(3)\n",
    "        faces.append(cell[0])\n",
    "        faces.append(cell[1])\n",
    "        faces.append(cell[2])\n",
    "    return np.array(faces)\n",
    "\n",
    "#Run function for creating Icosphere, and move sphere along x axis\n",
    "icosphere = createIcosphere(subdivisions=4, radius=0.5)\n",
    "icosphere.points[:, 0] += 0.55\n",
    "\n",
    "#Create a UV-Sphere for comparisons\n",
    "uvSphere = pv.Sphere(center=(-0.55, 0, 0))\n",
    "\n",
    "#Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(uvSphere, color='r')\n",
    "plotter.add_mesh(icosphere, color='b')\n",
    "plotter.add_mesh(icosphere.extract_all_edges(), color='white', opacity=0.6)\n",
    "plotter.add_mesh(uvSphere.extract_all_edges(), color='white', opacity=0.6)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f032f",
   "metadata": {},
   "source": [
    "Since we are dealing with spheres, it is useful to be able to switch between the usual XYZ cartesian coordinate system, and the spherical polar coordinates as shown in the image bellow. This will allow us to move vertices along a radial direction, which we will need to apply a heightmap onto a sphere.\n",
    "\n",
    "To convert from cartesian to polar coordinates, we use the following transformations:\n",
    "\n",
    "$$r = \\sqrt{x^2 + y^2 + z^2}$$\n",
    "$$\\theta = \\tan^{-1} (\\frac{y}{x})$$\n",
    "$$\\phi = \\cos^{-1} (\\frac{z}{r})$$\n",
    "\n",
    "and to convert back to cartesian coordinates:\n",
    "\n",
    "$$x = r \\cos \\theta \\sin \\phi$$\n",
    "$$y = r \\sin \\theta \\sin \\phi$$\n",
    "$$z = r \\cos \\phi$$\n",
    "\n",
    "By default, these functions will take angles in the form of degrees, which is suitable for longitudinal and latitudinal coordinates, however they can also accept angles in the form of radians by setting *useLonLat* to False. Since there are slight other variations of spherical polar coordinates, we provide a link bellow to the article that we will be basing ours on: <br>\n",
    "https://mathworld.wolfram.com/SphericalCoordinates.html \n",
    "\n",
    "<br>\n",
    "\n",
    "<div>\n",
    "<img src=\"Images/SphericalTransforms.jpg\" width=\"900\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccdba0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coordinate transformation from spherical polar to cartesian\n",
    "def polarToCartesian(radius, theta, phi, useLonLat=True):\n",
    "    if useLonLat == True:\n",
    "        theta, phi = np.radians(theta+180.), np.radians(90. - phi)\n",
    "    X = radius * np.cos(theta) * np.sin(phi)\n",
    "    Y = radius * np.sin(theta) * np.sin(phi)\n",
    "    Z = radius * np.cos(phi)\n",
    "    \n",
    "    print(type(X))\n",
    "    #Return data either as a list of XYZ coordinates or as a single XYZ coordinate\n",
    "    if (type(X) == np.ndarray):\n",
    "        return np.stack((X, Y, Z), axis=1)\n",
    "    else:\n",
    "        return np.array([X, Y, Z])\n",
    "\n",
    "#Coordinate transformation from cartesian to polar\n",
    "def cartesianToPolarCoords(XYZ, useLonLat=True):\n",
    "    X, Y, Z = XYZ[:, 0], XYZ[:, 1], XYZ[:, 2]\n",
    "    R = (X**2 + Y**2 + Z**2)**0.5\n",
    "    theta = np.arctan2(Y, X)\n",
    "    phi = np.arccos(Z / R)\n",
    "\n",
    "    #Return results either in spherical polar or leave it in radians\n",
    "    if useLonLat == True:\n",
    "        theta, phi = np.degrees(theta), np.degrees(phi)\n",
    "        lon, lat = theta - 180, 90 - phi\n",
    "        lon[lon < -180] = lon[lon < -180] + 360\n",
    "        return R, lon, lat\n",
    "    else:\n",
    "        return R, theta, phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da370b6",
   "metadata": {},
   "source": [
    "Now that we have defined our spherical polar coordinate transformations, we can use those to move vertices up or down along the radial direction of a sphere. For demonstrational purposes, we generate an Icosphere and sample noise from its vertices. We then use the coordinate transformations to set the radius of the sphere by some amount based on the sampled noise.\n",
    "\n",
    "By playing around with the parameters, we can get different results. For now, our noisy sphere looks like a meteorite, but by decreasing the noise amplitude we can make it a bit more earth like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ae1d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903bcf5468d14f90909af5e19f5e85cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903bcf5468d14f90909af5e19f5e85cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noiseAmplitude = 10000\n",
    "earthRadius = 6378000\n",
    "\n",
    "#Create an Icosphere and sample noise from its vertices to create a new radius.\n",
    "icosphere = createIcosphere(subdivisions=6, radius=earthRadius)\n",
    "noiseMap = sampleNoise(icosphere.points, initialFrequency=0.000001, octaves=8, octaveStepSize=1.5, amplitudeStepSize=2.4)\n",
    "noisyRadius =  earthRadius + noiseMap * noiseAmplitude * 30\n",
    "\n",
    "#Apply the noise radius to our sphere\n",
    "r, lon, lat = cartesianToPolarCoords(np.array(icosphere.points))\n",
    "noisySphereXYZ = polarToCartesian(noisyRadius, lon, lat)\n",
    "noisySphere = pv.PolyData(noisySphereXYZ, icosphere.faces)\n",
    "\n",
    "#Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(noisySphere, scalars=noiseMap)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc55b82e",
   "metadata": {},
   "source": [
    "In theory, although the above noise map does not look much like an earth like plannet, it is sufficient for randomly generating input elevation and uplift maps for GOSPL. After running multiple GOSPL simulation to get some training data, we can train our GAN, hopefully it learns the desired underlying geological phenomina and generalises well enough to be applied on more earth like inputs.\n",
    "\n",
    "In theory, the more diverse our data is, the more our GAN will generalize, so using multiple methods for creating input data should be beneficial. Also, there is no point for me to improve the input data if I later find out that we did not need to do so anyways. I don't actually know what to expect, but using this as input data will allow me to experiment with the GAN structure, and we can improve the input data afterwards if the GAN does not generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b134fb",
   "metadata": {},
   "source": [
    "# Gospl\n",
    "\n",
    "Gospl needs a zipped numpy array file *.NPZ* to specify the intial elevations of the planet. It must contain the following arrays:\n",
    "\n",
    "- **v**: **Vertices** - Of the original flat sphere\n",
    "- **c**: **Cells** - Details about the mesh connectivity\n",
    "- **n**: **Nearest Neighbours** - Details of each vertices neighbours\n",
    "- **z**: **Elevations** - The height at each vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9107b8d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './GeneratedData/initLandscape.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_109/2159191821.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0micosphere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0micosphere\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateInitialTopographyNPData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#Plot the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_109/2159191821.py\u001b[0m in \u001b[0;36mcreateInitialTopographyNPData\u001b[0;34m(octaves, subdivisions, octaveStepSize, earthRadius, noiseAmplitude, amplitudeStepSize, initialFrequency, fileName)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#Save the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez_compressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melevations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0micosphere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavez_compressed\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavez_compressed\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \"\"\"\n\u001b[0;32m--> 689\u001b[0;31m     \u001b[0m_savez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZIP_STORED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m     \u001b[0mzipf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnamedict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mzipfile_factory\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allowZip64'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './GeneratedData/initLandscape.npz'"
     ]
    }
   ],
   "source": [
    "#Create list of neighbour ids, based on bfModel notebook tutorial\n",
    "def getNeighbourIds(icoXYZ, icoCells):\n",
    "    Gmesh = meshplex.MeshTri(icoXYZ, icoCells)\n",
    "    s = Gmesh.idx_hierarchy.shape\n",
    "    a = np.sort(Gmesh.idx_hierarchy.reshape(s[0], -1).T)\n",
    "    Gmesh.edges = {'points': np.unique(a, axis=0)}\n",
    "    ngbNbs, ngbID = definegtin(len(icoXYZ), Gmesh.cells('points'), Gmesh.edges['points'])\n",
    "    ngbIDs = ngbID[:,:8].astype(int)\n",
    "    return ngbIDs\n",
    "\n",
    "#Create an array of elevations\n",
    "def addElevationsToSphere(icosphere, \n",
    "                           octaves=8, \n",
    "                           octaveStepSize=1.5, \n",
    "                           amplitudeStepSize=2.4,\n",
    "                           initialFrequency=0.000001):\n",
    "    noiseMap = sampleNoise(icosphere.points, \n",
    "                           octaves=octaves, \n",
    "                           octaveStepSize=octaveStepSize, \n",
    "                           amplitudeStepSize=amplitudeStepSize,\n",
    "                           initialFrequency=initialFrequency)\n",
    "    icosphere['elevations'] = noiseMap * noiseAmplitude + noiseAmplitude * 0.3\n",
    "    return icosphere\n",
    "    \n",
    "def createInitialTopographyNPData(\n",
    "                                octaves=8,\n",
    "                                subdivisions=6,\n",
    "                                octaveStepSize=1.5, \n",
    "                                earthRadius=6378000,\n",
    "                                noiseAmplitude=10000,\n",
    "                                amplitudeStepSize=2.4,\n",
    "                                initialFrequency=0.000001,\n",
    "                                fileName = './GeneratedData/initLandscape.npz'):\n",
    "    \n",
    "    #Create an Icosphere and get it's vertices and cells\n",
    "    icosphere = createIcosphere(subdivisions=subdivisions, radius=earthRadius)\n",
    "    vertices = icosphere.points\n",
    "\n",
    "    #Get the cell array that we attached to the icosphere mesh object earlier on\n",
    "    cells = icosphere['cells']\n",
    "    \n",
    "    icosphere = addElevationsToSphere(icosphere)\n",
    "    elevations = icosphere['elevations']\n",
    "\n",
    "    #Create a list of neighbour ids\n",
    "    neighbs = getNeighbourIds(vertices, cells)\n",
    "    \n",
    "    #Save the file\n",
    "    np.savez_compressed(fileName, v=vertices, c=cells, n=neighbs.astype(int), z=elevations)\n",
    "    return icosphere\n",
    "    \n",
    "icosphere = createInitialTopographyNPData()\n",
    "\n",
    "#Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(icosphere, scalars='elevations')\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of neighbour ids, based on bfModel notebook tutorial\n",
    "def getNeighbourIds(icoXYZ, icoCells):\n",
    "    Gmesh = meshplex.MeshTri(icoXYZ, icoCells)\n",
    "    s = Gmesh.idx_hierarchy.shape\n",
    "    a = np.sort(Gmesh.idx_hierarchy.reshape(s[0], -1).T)\n",
    "    Gmesh.edges = {'points': np.unique(a, axis=0)}\n",
    "    ngbNbs, ngbID = definegtin(len(icoXYZ), Gmesh.cells('points'), Gmesh.edges['points'])\n",
    "    ngbIDs = ngbID[:,:8].astype(int)\n",
    "    return ngbIDs\n",
    "\n",
    "#Create an Icosphere and get it's vertices and cells\n",
    "icosphere = createIcosphere(subdivisions=6, radius=earthRadius)\n",
    "vertices = icosphere.points\n",
    "\n",
    "#Get the cell array that we attached to the icosphere mesh object earlier on\n",
    "cells = icosphere['cells']\n",
    "\n",
    "icosphere = addElevationsToSphere(icosphere)\n",
    "elevations = icosphere['elevations']\n",
    "\n",
    "#Create a list of neighbour ids\n",
    "neighbs = getNeighbourIds(vertices, cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd35460e",
   "metadata": {},
   "source": [
    "# Generating Lots of Training Data\n",
    "\n",
    "In the code bellow, the function *runTrial()* will run a single gospl trial with the randomly generated input data above. The trials will be saved in a directory named *TrainingData*, and each trial will have their own *Tial{}* folder with some trial number. By running the *runTrial()* function multiple times, we will generate training data for our GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aae542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create one set of training data by running gospl\n",
    "def runTrial(dataDir = './TrainingData',\n",
    "            trialDirFormat = '{}/Trial{}',\n",
    "            npzDirFormat = '{}/NPZFiles',\n",
    "            initElevNPZformat = '{}/initElevations.npz',\n",
    "            ymlFileToCopy = 'NoiseSphereInput.yml'):\n",
    "    \n",
    "    #Make directory of training data if it does not already exist\n",
    "    if not os.path.isdir(dataDir):\n",
    "        os.mkdir(dataDir)\n",
    "\n",
    "    #Create a new subdirectories for each trial\n",
    "    trialNumber = 0\n",
    "    trialDir = trialDirFormat.format(dataDir, trialNumber)\n",
    "    while os.path.isdir(trialDir):\n",
    "        trialNumber += 1\n",
    "        trialDir = trialDirFormat.format(dataDir, trialNumber)\n",
    "    npzDir = npzDirFormat.format(trialDir)\n",
    "    initElevNPZ = initElevNPZformat.format(npzDir)\n",
    "    os.mkdir(trialDir)\n",
    "    os.mkdir(npzDir)\n",
    "    \n",
    "    #Create npz file if initial elevation\n",
    "    icosphere = createInitialTopographyNPData(fileName=initElevNPZ)\n",
    "    \n",
    "    #Read the YML file to copy\n",
    "    newYMLfileDir = trialDir + '/' + ymlFileToCopy\n",
    "    with open(ymlFileToCopy, 'r') as ymlFile:\n",
    "        ymlContent = ymlFile.read()\n",
    "        \n",
    "    #Fill in the missing blanks in the YML file and save it into the trial directory\n",
    "    ymlContent = ymlContent.format(trialDir, trialDir)\n",
    "    with open(newYMLfileDir, 'w') as newYMLfile:\n",
    "        newYMLfile.write(ymlContent)\n",
    "    \n",
    "    #Run simulation\n",
    "    mod = sim(newYMLfileDir, False, False)\n",
    "    mod.runProcesses()\n",
    "    mod.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8521d",
   "metadata": {},
   "source": [
    "Running the code bellow will generate training data until the user interupts. Since we will be needing lots of training data, we let this cell run overnight, and interupt it in the morning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "while False:\n",
    "    runTrial()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde4247",
   "metadata": {},
   "source": [
    "# Reading and Visualizing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "#The Gospl file contains simulation output data at particular iterations during the simulation\n",
    "def readGosplFile(fileDir):\n",
    "    gosplDict = {}\n",
    "    with h5py.File(fileDir, \"r\") as f:\n",
    "        for key in f.keys():\n",
    "            gosplDict[key] = np.array(f[key])\n",
    "    return gosplDict\n",
    "\n",
    "#Create a sphere from the gospl output topography files\n",
    "def createSphereMesh(topoXYZ):\n",
    "    r, lon, lat = cartesianToPolarCoords(topoXYZ)\n",
    "    lonLatFlat = np.stack((lon, lat, np.zeros(lon.shape))).T\n",
    "    faces = pv.PolyData(lonLatFlat).delaunay_2d().faces\n",
    "    return pv.PolyData(topoXYZ, faces)\n",
    "\n",
    "def createExageratedMesh(sphereMesh, keys, iteration=10, trialNumber=0):\n",
    "    dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(iteration)\n",
    "    data = readGosplFile(dataFile)\n",
    "    r, lon, lat = cartesianToPolarCoords(sphereMesh.points)\n",
    "    exegeratedRadius = earthRadius + 60 * data['elev']\n",
    "    sphereMesh.points =  polarToCartesian(exegeratedRadius[:, 0], lon, lat).T\n",
    "    for key in keys:\n",
    "        sphereMesh[key] = data[key]\n",
    "    return sphereMesh\n",
    "    \n",
    "    \n",
    "trialNumber = 0\n",
    "trialDataDirFormat = './TrainingData/Trial{}/NoiseSphere/h5/'\n",
    "gosplKeys = ['elev', 'erodep', 'fillFA', 'flowAcc', 'rain', 'sedLoad']\n",
    "\n",
    "#Read topology file\n",
    "topologyFile = trialDataDirFormat.format(trialNumber) + 'topology.p0.h5'\n",
    "topoDict = readGosplFile(topologyFile)\n",
    "sphereXYZ = topoDict['coords']\n",
    "sphereMesh = createSphereMesh(sphereXYZ)\n",
    "\n",
    "#Read simulation data at iteration\n",
    "iteration = 0\n",
    "dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(iteration)\n",
    "dataDict = readGosplFile(dataFile)\n",
    "print(dataDict.keys())\n",
    "\n",
    "planetMesh = createExageratedMesh(sphereMesh, gosplKeys, iteration=iteration, trialNumber=trialNumber)\n",
    "\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(planetMesh, scalars=dataDict['flowAcc']**0.25)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e86f5",
   "metadata": {},
   "source": [
    "The code bellow generates animations of our GOSPL simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37171d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animateGosplResults(trialNumber, \n",
    "                        iterations=10, \n",
    "                        framesPerIteration=8, \n",
    "                        scalarToPlot='elev',\n",
    "                       animationDir='ErosionAnimation.mp4'):\n",
    "    \n",
    "    topologyFile = trialDataDirFormat.format(trialNumber) + 'topology.p0.h5'\n",
    "    topoDict = readGosplFile(topologyFile)\n",
    "    sphereXYZ = topoDict['coords']\n",
    "    sphereMesh = createSphereMesh(sphereXYZ)\n",
    "\n",
    "    #Create initial planet mesh\n",
    "    dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(0)\n",
    "    dataDict = readGosplFile(dataFile)\n",
    "    planetMesh = createExageratedMesh(sphereMesh, gosplKeys, iteration=0, trialNumber=trialNumber)\n",
    "\n",
    "    #Initiate the plotter for animation\n",
    "    plotter = pv.Plotter()\n",
    "    plannetActor = plotter.add_mesh(planetMesh, scalars=dataDict[scalarToPlot])\n",
    "    plotter.camera.zoom(1.4)\n",
    "    plotter.open_movie(animationDir)\n",
    "    for i in range(framesPerIteration):\n",
    "        plotter.write_frame()\n",
    "\n",
    "    #Loop through all iteration data files and draw animation frames\n",
    "    for i in range(iterations):\n",
    "        dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(i+1)\n",
    "        dataDict = readGosplFile(dataFile)\n",
    "        planetMesh = createExageratedMesh(sphereMesh, gosplKeys, iteration=i+1, trialNumber=trialNumber)\n",
    "        newScalars = dataDict[scalarToPlot]\n",
    "\n",
    "        #Draw animation frames\n",
    "        plotter.remove_actor(plannetActor)\n",
    "        plannetActor = plotter.add_mesh(planetMesh, scalars=dataDict[scalarToPlot])\n",
    "        for i in range(framesPerIteration):\n",
    "            plotter.write_frame()\n",
    "    plotter.close()\n",
    "\n",
    "animateGosplResults(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600e632",
   "metadata": {},
   "source": [
    "# Preprocess Data for Tensorflow\n",
    "\n",
    "Many machine learning libraries such as tensorflow have plenty of tools and algorithms built in to deal with image type data, so to keep things simple, we would like to convert our data set into an image representation. This will allow us to use convolutional layers in our neural network (NN), which tends to perform really well in images.\n",
    "\n",
    "Note that many of the novel NN based physics simulators use graph based methods, and generalize the convolutional layer into a general graph rather than restricting it on a 2D image format. Although this is the approach we might want to use in the future, these methods have only been around for a few years, and the tools for graph based methods are not as well established as compared to the usual image convolution layers. So to keep things simple for now, we will represent our data as images.\n",
    "\n",
    "To convert our data into image representations, we will interpolate our data into UV sphere. The lon/lat coordinates of vertices of a UV sphere can then be represented as the XY location that they fall into in the image, and parameters such as elevation and erosion deposition can be represented using the RGB channels of the image.\n",
    "\n",
    "The code bellow demonstrates how we can convert a UV sphere into a flat grid. Note that we will need to remove the vertices on the north/south poles to make this work. This grid can then be represented as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create UV sphere\n",
    "uvSphere = pv.Sphere()\n",
    "r, theta, phi = cartesianToPolarCoords(uvSphere.points)\n",
    "theta[theta<=0] += 360\n",
    "\n",
    "#Convert to flat point cloud\n",
    "zeros = np.zeros(theta.shape)\n",
    "XYZ = np.array([zeros, theta, phi]).T\n",
    "\n",
    "#Remove first two coordinates corresponding to north and south pole\n",
    "XYZ = XYZ[2:, :]\n",
    "\n",
    "lonLatPointCloud = pv.PolyData(XYZ)\n",
    "colors = np.arange(XYZ.shape[0])\n",
    "\n",
    "#Plot results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(lonLatPointCloud, scalars=colors)\n",
    "plotter.background_color  = 'grey'\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157bdeb",
   "metadata": {},
   "source": [
    "We now need to interpolate our data onto a UV sphere. To do so, we will need the lon/lat coordinates of the Icosphere to interpolate from, the lon/lat coordinates of the UV sphere to interpolate onto, and the data to interpolate. We can then use the griddata interpolator form the scipy library.\n",
    "\n",
    "Note that since images have 3 color channels (RGB), we can use 3 scalar values produced by Gospl in the image. This will give more data for our NN to work with. In the code bellow, we interpolate elevation, erosion deposition and flow accumulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd47d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create lon/lat from gospl's icosphere to interpolate from\n",
    "def getIcoLonLat(trialNumber=0):\n",
    "    topologyFile = trialDataDirFormat.format(trialNumber) + 'topology.p0.h5'\n",
    "    topoDict = readGosplFile(topologyFile)\n",
    "    icoSphereXYZ = topoDict['coords']\n",
    "    icoSphereMesh = createSphereMesh(icoSphereXYZ)\n",
    "    _, icoLon, icoLat = cartesianToPolarCoords(icoSphereXYZ)\n",
    "    icoLon[icoLon<=0] += 360\n",
    "    return np.array([icoLon, icoLat]).T\n",
    "\n",
    "#Create lon/lat to interpolate onto\n",
    "def getUVLonLat(resolution=[512, 258]):\n",
    "    uvSphere = pv.Sphere(theta_resolution=resolution[0], phi_resolution=resolution[1])\n",
    "    _, uvLon, uvLat = cartesianToPolarCoords(uvSphere.points)\n",
    "    uvLon[uvLon<=0] += 360\n",
    "    return np.array([uvLon, uvLat]).T\n",
    "\n",
    "#Use griddata interpolation to get scalars of the UV sphere\n",
    "def getInterpolatedData(trialNumber, iteration, icoLonLat, uvLonLat,\n",
    "                        scalarsToInterpolate=['elev', 'erodep', 'flowAcc']):\n",
    "    \n",
    "    #Get data to interpolate\n",
    "    dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(iteration)\n",
    "    dataDict = readGosplFile(dataFile)\n",
    "    interpolatedScalars = []\n",
    "    \n",
    "    #Loop through all scalars to interpolate\n",
    "    for scalar in scalarsToInterpolate:\n",
    "        newScalar = griddata(icoLonLat, dataDict[scalar], uvLonLat)\n",
    "        whereNAN = np.argwhere(np.isnan(newScalar))\n",
    "        newScalar[whereNAN] = griddata(icoLonLat, dataDict[scalar], uvLonLat[whereNAN], method='nearest')\n",
    "        interpolatedScalars.append(newScalar)\n",
    "    return np.array(interpolatedScalars).T[0]\n",
    "\n",
    "trialNumber = 25\n",
    "iteration = 10\n",
    "\n",
    "#Get interpolated data for the UV sphere\n",
    "uvLonLat = getUVLonLat()\n",
    "icoLonLat = getIcoLonLat()\n",
    "interpolatedData = getInterpolatedData(trialNumber, iteration, icoLonLat, uvLonLat)\n",
    "\n",
    "#Plot results\n",
    "plotter = pv.PlotterITK()\n",
    "uvSphere = pv.Sphere(theta_resolution=512, phi_resolution=258)\n",
    "plotter.add_mesh(uvSphere, scalars=interpolatedData[:, 0])\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae586ae",
   "metadata": {},
   "source": [
    "Now that we have the data interpolated onto a UV sphere, we can represent it by an image. First we reshape the data array into an image shape, and then bring all values to a range from 0 to 255 as required for 8 bit pixels. We also raise the flow accumulation variable by the power of 0.125, to make it's distribution more linear and therefore more visible.\n",
    "\n",
    "Note, that we may need 16 bit images if 8 bit is does not provide sufficient tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4dc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The interpolated data is save in the RGB channels of the image\n",
    "#We bring data into range from 0 to 255, as required for images\n",
    "def createImage(rgb):\n",
    "    RGB = np.copy(rgb)\n",
    "    RGB = RGB[2:].reshape(512, 256, 3)\n",
    "    RGB[:, :, 2] = RGB[:, :, 2]**0.125\n",
    "    RGB -= np.min(interpolatedData, axis=0)\n",
    "    RGB[:, :, 0] /= np.max(RGB[:, :, 0])\n",
    "    RGB[:, :, 2] /= np.max(RGB[:, :, 2])\n",
    "    if np.max(RGB[:, :, 1]) != 0:\n",
    "        RGB[:, :, 1] /= np.max(RGB[:, :, 1])\n",
    "    RGB *= 255\n",
    "    return Image.fromarray(RGB.astype(np.uint8))\n",
    "\n",
    "trialNumber = 25\n",
    "iteration = 10\n",
    "\n",
    "#Get data to be represented by images\n",
    "uvLonLat = getUVLonLat()\n",
    "icoLonLat = getIcoLonLat()\n",
    "interpolatedData = getInterpolatedData(trialNumber, iteration, icoLonLat, uvLonLat)\n",
    "\n",
    "#Display or save image\n",
    "img = createImage(interpolatedData)\n",
    "img.save('testImage.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261795e9",
   "metadata": {},
   "source": [
    "We probably also want to make sure we can read images back into a spherical mesh format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthRadius = 6378000\n",
    "rangeMax = np.array([9.21434829e+03, 5.20667833e+03, 3.23146528e+14])\n",
    "rangeMin = np.array([-9.62599721e+02, -1.49130044e+03,  1.00000000e+00])\n",
    "\n",
    "#Read image for heights data\n",
    "image = Image.open(\"testImage.png\")\n",
    "dataArray = np.array(image)\n",
    "heights = dataArray[:, :,0]\n",
    "heights = heights * (rangeMax[0] - rangeMin[0]) / 255 + rangeMin[0]\n",
    "\n",
    "#Insert back the north and south pole, for now we just let it be zero, but we can interpolate to get a better value\n",
    "heights = np.insert(heights, 0, 0)\n",
    "heights = np.insert(heights, 0, 0)\n",
    "\n",
    "#Apply the noise radius to our sphere\n",
    "uvSphere = pv.Sphere(radius=earthRadius, theta_resolution=512, phi_resolution=258)\n",
    "r, lon, lat = cartesianToPolarCoords(np.array(uvSphere.points))\n",
    "noisySphereXYZ = polarToCartesian(heights * 60 + earthRadius, lon, lat)\n",
    "noisySphere = pv.PolyData(noisySphereXYZ, uvSphere.faces)\n",
    "\n",
    "#Plot results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(noisySphere, scalars=heights)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebfd3c1",
   "metadata": {},
   "source": [
    "Now that we have a way of representing our data as images, we wan't to convert all our data files into data for tensorflow. For each feature (input data), we want the target (output of NN) to be the next iteration of the GOSPL simulation. So each iteration will be a sample with the next iteration as the target data.\n",
    "\n",
    "In machine learning literature, a feature is the input of a model such as an NN, and the target is the output of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a803260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialNumber = 25\n",
    "iteration = 10\n",
    "\n",
    "#Get data to be represented by images\n",
    "uvLonLat = getUVLonLat()\n",
    "icoLonLat = getIcoLonLat()\n",
    "\n",
    "#Loop through all images and save feature/target image pairs\n",
    "count = 0\n",
    "if False:\n",
    "    for trial in range(360):\n",
    "        for i in range(iteration):\n",
    "            featureData = getInterpolatedData(trial, i, icoLonLat, uvLonLat)\n",
    "            featureImage = createImage(featureData)\n",
    "            featureImage.save('./ImageTrainingData/Features/feature{}.png'.format(count))\n",
    "\n",
    "            targetData = getInterpolatedData(trial, i+1, icoLonLat, uvLonLat)\n",
    "            targetImage = createImage(targetData)\n",
    "            targetImage.save('./ImageTrainingData/Targets/target{}.png'.format(count))\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Crash Python Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69ea14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createImage(rgb):\n",
    "    RGB = np.copy(rgb)\n",
    "    RGB = RGB[2:].reshape(512, 256, 3)\n",
    "    RGB[:, :, 2] = RGB[:, :, 2]**0.125\n",
    "    RGB -= np.min(interpolatedData, axis=0)\n",
    "    RGB[:, :, 0] /= np.max(RGB[:, :, 0])\n",
    "    #RGB[:, :, 2] /= np.max(RGB[:, :, 2])\n",
    "    #if np.max(RGB[:, :, 1]) != 0:\n",
    "    #    RGB[:, :, 1] /= np.max(RGB[:, :, 1])\n",
    "    RGB *= 255\n",
    "    return Image.fromarray(RGB.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa5f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialNumber = 25\n",
    "iteration = 10\n",
    "\n",
    "#Get data to be represented by images\n",
    "uvLonLat = getUVLonLat()\n",
    "icoLonLat = getIcoLonLat()\n",
    "\n",
    "#Loop through all images and save feature/target image pairs\n",
    "count = 0\n",
    "if False:\n",
    "    for trial in range(360):\n",
    "        for i in range(iteration):\n",
    "            #featureData = getInterpolatedData(trial, i, icoLonLat, uvLonLat)\n",
    "            #featureImage = createImage(featureData)\n",
    "            #featureImage.save('./ImageTrainingData/Features/feature{}.png'.format(count))\n",
    "\n",
    "            targetData = getInterpolatedData(trial, i+1, icoLonLat, uvLonLat)\n",
    "            targetImage = createImage(targetData)\n",
    "            targetImage.save('./ImageTrainingData/TargetsGray/target{}.png'.format(count))\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a26bfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc284b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createImage(rgb):\n",
    "    RGB = np.copy(rgb)\n",
    "    RGB = RGB[2:].reshape(512, 256, 3)\n",
    "    RGB[:, :, 2] = RGB[:, :, 2]**0.125\n",
    "    RGB[:, :, 0] -= np.min(RGB[:, :, 0])\n",
    "    RGB[:, :, 1] -= np.min(RGB[:, :, 1])\n",
    "    RGB[:, :, 2] -= np.min(RGB[:, :, 2])\n",
    "    RGB[:, :, 0] /= np.max(RGB[:, :, 0])\n",
    "    RGB[:, :, 2] /= np.max(RGB[:, :, 2])\n",
    "    if np.max(RGB[:, :, 1]) != 0:\n",
    "        RGB[:, :, 1] /= np.max(RGB[:, :, 1])\n",
    "    RGB *= 255\n",
    "    return Image.fromarray(RGB.astype(np.uint8))\n",
    "\n",
    "img = createImage(rgb)\n",
    "#img.save('my.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9463b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialNumber = 2\n",
    "iteration = 10\n",
    "\n",
    "#Get Gospl data\n",
    "dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(iteration)\n",
    "dataDict = readGosplFile(dataFile)\n",
    "\n",
    "#Create lon/lat from gospl's icosphere tp interpolate from\n",
    "topologyFile = trialDataDirFormat.format(trialNumber) + 'topology.p0.h5'\n",
    "topoDict = readGosplFile(topologyFile)\n",
    "icoSphereXYZ = topoDict['coords']\n",
    "icoSphereMesh = createSphereMesh(icoSphereXYZ)\n",
    "_, icoLon, icoLat = cartesianToPolarCoords(icoSphereXYZ)\n",
    "icoLon[icoLon<=0] += 360\n",
    "icoLonLat = np.array([icoLon, icoLat]).T\n",
    "\n",
    "#Create lon/lat to interpolate onto\n",
    "uvSphere = pv.Sphere(theta_resolution=512, phi_resolution=258)\n",
    "_, uvLon, uvLat = cartesianToPolarCoords(uvSphere.points)\n",
    "uvLon[uvLon<=0] += 360\n",
    "uvLonLat = np.array([uvLon, uvLat]).T\n",
    "\n",
    "interpolatedScalars = []\n",
    "scalarsToInterpolate = ['elev', 'erodep', 'flowAcc']#, 'fillFA']\n",
    "for scalar in scalarsToInterpolate:\n",
    "    newScalar = griddata(icoLonLat, dataDict[scalar], uvLonLat)\n",
    "    whereNAN = np.argwhere(np.isnan(newScalar))\n",
    "    newScalar[whereNAN] = griddata(icoLonLat, dataDict[scalar], uvLonLat[whereNAN], method='nearest')\n",
    "    interpolatedScalars.append(newScalar)\n",
    "interpolatedScalars = np.array(interpolatedScalars)\n",
    "\n",
    "#Plot results\n",
    "plotter = pv.PlotterITK()\n",
    "#plotter.add_mesh(icoSphereMesh, scalars=dataDict['elev'])\n",
    "plotter.add_mesh(uvSphere, scalars=interpolatedScalars[0])\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB = np.copy(interpolatedScalars.T[0])\n",
    "RGB = RGB[2:].reshape(512, 256, 3)\n",
    "\n",
    "RGB[:, :, 0] -= np.min(RGB[:, :, 0])\n",
    "RGB[:, :, 1] -= np.min(RGB[:, :, 1])\n",
    "RGB[:, :, 2] -= np.min(RGB[:, :, 2])\n",
    "RGB[:, :, 2] = RGB[:, :, 2]**0.125\n",
    "\n",
    "RGB[:, :, 0] /= np.max(RGB[:, :, 0])\n",
    "RGB[:, :, 1] /= np.max(RGB[:, :, 1])\n",
    "RGB[:, :, 2] /= np.max(RGB[:, :, 2])\n",
    "RGB *= 255\n",
    "\n",
    "img = Image.fromarray(RGB.astype(np.uint8))\n",
    "#img.save('my.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e01116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "print(RGB.shape)\n",
    "print(np.max(RGB))\n",
    "\n",
    "img = Image.fromarray(RGB.astype(np.uint8))\n",
    "img.save('my.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c67f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uvLonLat.shape)\n",
    "print(np.unique(uvLonLat[2:, 1]).shape)\n",
    "print(np.unique(uvLon).shape)\n",
    "print(np.unique(uvLat).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"./Images/IcoVsUVSphere.PNG\")\n",
    "np_array = np.array(image)\n",
    "print(np_array.shape)\n",
    "print(np_array.astype(int))\n",
    "print(np.min(np_array))\n",
    "\n",
    "pil_image=Image.fromarray(np_array)\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdab381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2564db10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ac742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialNumber = 0\n",
    "iterations = 10\n",
    "framesPerIteration = 8\n",
    "trialDataDirFormat = './TrainingData/Trial{}/NoiseSphere/h5/'\n",
    "gosplKeys = ['elev', 'erodep', 'fillFA', 'flowAcc', 'rain', 'sedLoad']\n",
    "scalarToPlot = 'elev'\n",
    "\n",
    "#Read topology file\n",
    "topologyFile = trialDataDirFormat.format(trialNumber) + 'topology.p0.h5'\n",
    "topoDict = readGosplFile(topologyFile)\n",
    "sphereXYZ = topoDict['coords']\n",
    "sphereMesh = createSphereMesh(sphereXYZ)\n",
    "\n",
    "#Create initial planet mesh\n",
    "dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(0)\n",
    "dataDict = readGosplFile(dataFile)\n",
    "planetMesh = createExageratedMesh(sphereMesh, gosplKeys, iteration=0)\n",
    "\n",
    "#Initiate the plotter for animation\n",
    "plotter = pv.Plotter()\n",
    "plannetActor = plotter.add_mesh(planetMesh, scalars=dataDict[scalarToPlot])\n",
    "plotter.camera.zoom(1.4)\n",
    "plotter.open_movie('ErosionAnimation.mp4')\n",
    "for i in range(framesPerIteration):\n",
    "    plotter.write_frame()\n",
    "\n",
    "#Loop through all iteration data files and draw animation frames\n",
    "for i in range(iterations):\n",
    "    dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(i+1)\n",
    "    dataDict = readGosplFile(dataFile)\n",
    "    planetMesh = createExageratedMesh(sphereMesh, gosplKeys, iteration=i+1)\n",
    "    newScalars = dataDict[scalarToPlot]\n",
    "    \n",
    "    #Draw animation frames\n",
    "    plotter.remove_actor(plannetActor)\n",
    "    plannetActor = plotter.add_mesh(planetMesh, scalars=dataDict[scalarToPlot])\n",
    "    for i in range(framesPerIteration):\n",
    "        plotter.write_frame()\n",
    "plotter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dfc53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a01ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseAmplitude=10000\n",
    "earthRadius=6378000\n",
    "\n",
    "#Create an Icosphere and get it's vertices and cells\n",
    "icosphere = createIcosphere(subdivisions=6, radius=earthRadius)\n",
    "vertices = icosphere.points\n",
    "\n",
    "#Get the cell array that we attached to the icosphere mesh object earlier on\n",
    "cells = icosphere['cells']\n",
    "\n",
    "#Create an array of elevations\n",
    "noiseMap = sampleNoise(icosphere.points, initialFrequency=0.000001, octaves=8, octaveStepSize=1.5, amplitudeStepSize=2.4)\n",
    "elevations = earthRadius + noiseMap * noiseAmplitude\n",
    "\n",
    "#Create a list of neighbour ids\n",
    "neighbs = getNeighbourIds(vertices, cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseAmplitude = 10000\n",
    "earthRadius = 6378000\n",
    "\n",
    "#Create an Icosphere and sample noise from its vertices to create a new radius.\n",
    "icosphere = createIcosphere(subdivisions=6, radius=earthRadius)\n",
    "noiseMap = sampleNoise(icosphere.points, initialFrequency=0.000001, octaves=8, octaveStepSize=1.5, amplitudeStepSize=2.4)\n",
    "noisyRadius =  earthRadius + noiseMap * noiseAmplitude * 30\n",
    "\n",
    "#Apply the noise radius to our sphere\n",
    "r, lon, lat = cartesianToPolarCoords(np.array(icosphere.points))\n",
    "noisySphereXYZ = polarToCartesian(noisyRadius, lon, lat)\n",
    "noisySphere = pv.PolyData(noisySphereXYZ, icosphere.faces)\n",
    "\n",
    "#Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(noisySphere, scalars=noiseMap)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132371a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594d815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshplex\n",
    "\n",
    "icosphere = stripy.spherical_meshes.icosahedral_mesh( \n",
    "                refinement_levels = 6,\n",
    "                include_face_points = False)\n",
    "icosphereXYZ = icosphere._points * 1.0\n",
    "icoFaces = stripyCellsToPyvistaFaces(icosphere.simplices)\n",
    "\n",
    "Gmesh = meshplex.MeshTri(icosphereXYZ, icosphere.simplices)\n",
    "\n",
    "print(Gmesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768c98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57426b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
