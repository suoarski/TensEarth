{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be310a6",
   "metadata": {},
   "source": [
    "# Aim\n",
    "\n",
    "In this project, we would like to train a Generative Adversarial Network (GAN) to simulate dynamic earth processes from data generated by GOSPL. To do so, we will first need to generate a lot of data that our GAN can learn from. In this notebook, we will use noise based methods to initiate many GOSPL simulations, which we will use as training data for our GAN. \n",
    "\n",
    "At this stage of the project, I keep the random data generation as simple as possible, so I can focus on testing out different GANs. This will serve as a proof of concept, and once I have a GAN that can faithfully learn from our simple data, we can then focus on generating more diverse GOSPL simulations.\n",
    "\n",
    "# Running this Notebook\n",
    "\n",
    "To run this notebook, I reccomend using [this docker environment for GOSPL](https://hub.docker.com/r/geodels/gospl). The main libraries needed here are GOSPL and Pyvista. In the next notebook, we will not be using GOSPL, but tensorflow instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c39a6a",
   "metadata": {},
   "source": [
    "# Noise\n",
    "\n",
    "To randomly generate input data for GOSPL, we will need to generate random noise. We will be taking advantage of the pyvista perlin noise function as our base source of noise. Note that the *pv.perlin_noise* function is fairly new to pyvista and so we must use the latest version of pyvista to take advantage of it.\n",
    "\n",
    "The perlin noise function always returns the exact same values if the input is the same, making it not random. To make it pseudo random, we will pass it a random phase offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9479fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import stripy\n",
    "import meshplex\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from gospl.model import Model as sim\n",
    "from gospl._fortran import definegtin\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3ef1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6061a3d0c8524452b7281b459c01639e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6061a3d0c8524452b7281b459c01639e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Given a list of XYZ coordinates, we sample a noise value at each point\n",
    "def samplePerlinNoise(XYZ, amplitude=1, frequency=4, offset=None):\n",
    "    if offset == None: #Random offset if none other is specified\n",
    "        offset = np.random.rand(3) * 100000\n",
    "    freq = (frequency, frequency, frequency)\n",
    "    noise = pv.perlin_noise(amplitude, freq, offset)\n",
    "    return np.array([noise.EvaluateFunction(xyz) for xyz in XYZ])\n",
    "    \n",
    "#Create a plane, sample noise and apply noise to heights of points on plane\n",
    "plane = pv.Plane(i_size=10, j_size=10, i_resolution=400, j_resolution=400)\n",
    "noiseSamples = samplePerlinNoise(plane.points)\n",
    "plane.points[:, 2] += noiseSamples * 0.1\n",
    "\n",
    "#Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(plane, scalars=noiseSamples)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ae9d9",
   "metadata": {},
   "source": [
    "The above noise function only has a single frequency within it, and therefore looks a bit too artificial. To make the noise look more natural, we will sum up multiple noise samples, each with their own frequency and amplitude. We refer to each noise sample as an octave of the final noise. Given a specified initial frequency, each octave will have a frequency of:\n",
    "\n",
    "$$ f_{oct} = f_{init}  s_o ^ i$$\n",
    "\n",
    "where $s_o$ is the octave step size and $i$ is the current number of the current octave. Each noise sample will have a decreasing amplitude based on the amplitude step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46fc701b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64f38fc03e040d585541f5ea66b485e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64f38fc03e040d585541f5ea66b485e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sample noise with multiple noise frequencies\n",
    "def sampleNoise(XYZ, initialFrequency=1, octaves=8, octaveStepSize=1.4, amplitudeStepSize=2):\n",
    "    noiseSum = np.zeros(XYZ.shape[0])\n",
    "    for i in range(octaves):\n",
    "        frequency =  initialFrequency * octaveStepSize ** i\n",
    "        noiseSum += samplePerlinNoise(XYZ, frequency=frequency) / (amplitudeStepSize*(i+1))\n",
    "    return noiseSum\n",
    "\n",
    "#Create a plane, sample noise and apply noise to heights of points on plane\n",
    "plane = pv.Plane(i_size=10, j_size=10, i_resolution=400, j_resolution=400)\n",
    "noiseSamples = sampleNoise(plane.points)\n",
    "plane.points[:, 2] += noiseSamples * 0.4\n",
    "\n",
    "#Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(plane, scalars=noiseSamples)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128c137",
   "metadata": {},
   "source": [
    "# Spheres\n",
    "\n",
    "Although pyvista does have a built in function for creating spheres, it returns a UV sphere. Since GOSPL requires an Icosphere, we will generate one from the *stripy* library and convert it to a pyvista object instead. In the code bellow, we generate an Icosphere and convert it to a pyvista object. We then plot the Icosphere in blue, and a UV sphere in red for comparisons. Notice how the layout of vertices and edges are different.\n",
    "\n",
    "Since we will be needing the cell array generated by stripy later on, we can store this array within the pyvista mesh object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10081f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934a088181824527818ce1861bfafe35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934a088181824527818ce1861bfafe35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a pyvista icosphere from stripy library (since pyvista doesn't have an Icosphere)\n",
    "def createIcosphere(subdivisions=6, radius=6378137):\n",
    "    icosphere = stripy.spherical_meshes.icosahedral_mesh( \n",
    "                    refinement_levels = subdivisions,\n",
    "                    include_face_points = False)\n",
    "    icosphereXYZ = icosphere._points * radius\n",
    "    icoFaces = stripyCellsToPyvistaFaces(icosphere.simplices)\n",
    "    icoMesh = pv.PolyData(icosphereXYZ, icoFaces)\n",
    "    icoMesh['cells'] = icosphere.simplices\n",
    "    return icoMesh\n",
    "\n",
    "#Create an array for the pyvista faces based on stripy cells\n",
    "def stripyCellsToPyvistaFaces(cells):\n",
    "    faces = []\n",
    "    for cell in cells:\n",
    "        faces.append(3)\n",
    "        faces.append(cell[0])\n",
    "        faces.append(cell[1])\n",
    "        faces.append(cell[2])\n",
    "    return np.array(faces)\n",
    "\n",
    "#Run function for creating Icosphere, and move sphere along x axis\n",
    "icosphere = createIcosphere(subdivisions=4, radius=0.5)\n",
    "icosphere.points[:, 0] += 0.55\n",
    "\n",
    "#Create a UV-Sphere for comparisons\n",
    "uvSphere = pv.Sphere(center=(-0.55, 0, 0))\n",
    "\n",
    "#Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(uvSphere, color='r')\n",
    "plotter.add_mesh(icosphere, color='b')\n",
    "plotter.add_mesh(icosphere.extract_all_edges(), color='white', opacity=0.6)\n",
    "plotter.add_mesh(uvSphere.extract_all_edges(), color='white', opacity=0.6)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f032f",
   "metadata": {},
   "source": [
    "Since we are dealing with spheres, it is useful to be able to switch between the usual XYZ cartesian coordinate system, and the spherical polar coordinates as shown in the image bellow. This will allow us to move vertices along a radial direction, which we will need to apply a heightmap onto a sphere.\n",
    "\n",
    "To convert from cartesian to polar coordinates, we use the following transformations:\n",
    "\n",
    "$$r = \\sqrt{x^2 + y^2 + z^2}$$\n",
    "$$\\theta = \\tan^{-1} (\\frac{y}{x})$$\n",
    "$$\\phi = \\cos^{-1} (\\frac{z}{r})$$\n",
    "\n",
    "and to convert back to cartesian coordinates:\n",
    "\n",
    "$$x = r \\cos \\theta \\sin \\phi$$\n",
    "$$y = r \\sin \\theta \\sin \\phi$$\n",
    "$$z = r \\cos \\phi$$\n",
    "\n",
    "By default, these functions will take angles in the form of degrees, which is suitable for longitudinal and latitudinal coordinates, however they can also accept angles in the form of radians by setting *useLonLat* to False. Since there are slight other variations of spherical polar coordinates, we provide a link bellow to the article that we will be basing ours on: <br>\n",
    "https://mathworld.wolfram.com/SphericalCoordinates.html \n",
    "\n",
    "<br>\n",
    "\n",
    "<div>\n",
    "<img src=\"NotebookImages/SphericalTransforms.jpg\" width=\"900\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccdba0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coordinate transformation from spherical polar to cartesian\n",
    "def polarToCartesian(radius, theta, phi, useLonLat=True):\n",
    "    if useLonLat == True:\n",
    "        theta, phi = np.radians(theta+180.), np.radians(90. - phi)\n",
    "    X = radius * np.cos(theta) * np.sin(phi)\n",
    "    Y = radius * np.sin(theta) * np.sin(phi)\n",
    "    Z = radius * np.cos(phi)\n",
    "    \n",
    "    #Return data either as a list of XYZ coordinates or as a single XYZ coordinate\n",
    "    if (type(X) == np.ndarray):\n",
    "        return np.stack((X, Y, Z), axis=1)\n",
    "    else:\n",
    "        return np.array([X, Y, Z])\n",
    "\n",
    "#Coordinate transformation from cartesian to polar\n",
    "def cartesianToPolarCoords(XYZ, useLonLat=True):\n",
    "    X, Y, Z = XYZ[:, 0], XYZ[:, 1], XYZ[:, 2]\n",
    "    R = (X**2 + Y**2 + Z**2)**0.5\n",
    "    theta = np.arctan2(Y, X)\n",
    "    phi = np.arccos(Z / R)\n",
    "\n",
    "    #Return results either in spherical polar or leave it in radians\n",
    "    if useLonLat == True:\n",
    "        theta, phi = np.degrees(theta), np.degrees(phi)\n",
    "        lon, lat = theta - 180, 90 - phi\n",
    "        lon[lon < -180] = lon[lon < -180] + 360\n",
    "        return R, lon, lat\n",
    "    else:\n",
    "        return R, theta, phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da370b6",
   "metadata": {},
   "source": [
    "Now that we have defined our spherical polar coordinate transformations, we can use those to move vertices up or down along the radial direction of a sphere. For demonstrational purposes, we generate an Icosphere and sample noise from its vertices. We then use the coordinate transformations to set the radius of the sphere by some amount based on the sampled noise.\n",
    "\n",
    "By playing around with the parameters, we can get different results. For now, our noisy sphere looks like a meteorite, but by decreasing the noise amplitude we can make it a bit more earth like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ae1d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba4a7256ffa4690a0fddb054b24f1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba4a7256ffa4690a0fddb054b24f1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noiseAmplitude = 10000\n",
    "earthRadius = 6378000\n",
    "\n",
    "#Create an Icosphere and sample noise from its vertices to create a new radius.\n",
    "icosphere = createIcosphere(subdivisions=6, radius=earthRadius)\n",
    "noiseMap = sampleNoise(icosphere.points, initialFrequency=0.000001, octaves=8, octaveStepSize=1.5, amplitudeStepSize=2.4)\n",
    "noisyRadius =  earthRadius + noiseMap * noiseAmplitude * 30\n",
    "\n",
    "#Apply the noise radius to our sphere\n",
    "r, lon, lat = cartesianToPolarCoords(np.array(icosphere.points))\n",
    "noisySphereXYZ = polarToCartesian(noisyRadius, lon, lat)\n",
    "noisySphere = pv.PolyData(noisySphereXYZ, icosphere.faces)\n",
    "\n",
    "#Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(noisySphere, scalars=noiseMap)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc55b82e",
   "metadata": {},
   "source": [
    "In theory, although the above noise map does not look much like an earth like plannet, it is sufficient for randomly generating input elevation and uplift maps for GOSPL. After running multiple GOSPL simulation to get some training data, we can train our GAN, hopefully it learns the desired underlying geological phenomina and generalises well enough to be applied on more earth like inputs.\n",
    "\n",
    "In theory, the more diverse our data is, the more our GAN will generalize, so using multiple methods for creating input data should be beneficial. Also, there is no point for me to improve the input data if I later find out that we did not need to do so anyways. I don't actually know what to expect, but using this as input data will allow me to experiment with the GAN structure, and we can improve the input data afterwards if the GAN does not generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b134fb",
   "metadata": {},
   "source": [
    "# Gospl\n",
    "\n",
    "Gospl needs a zipped numpy array file *.NPZ* to specify the intial elevations of the planet. It must contain the following arrays:\n",
    "\n",
    "- **v**: **Vertices** - Of the original flat sphere\n",
    "- **c**: **Cells** - Details about the mesh connectivity\n",
    "- **n**: **Nearest Neighbours** - Details of each vertices neighbours\n",
    "- **z**: **Elevations** - The height at each vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9107b8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f91708311024b67b532dbb30f012c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f91708311024b67b532dbb30f012c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create list of neighbour ids, based on bfModel notebook tutorial\n",
    "def getNeighbourIds(icoXYZ, icoCells):\n",
    "    Gmesh = meshplex.MeshTri(icoXYZ, icoCells)\n",
    "    s = Gmesh.idx_hierarchy.shape\n",
    "    a = np.sort(Gmesh.idx_hierarchy.reshape(s[0], -1).T)\n",
    "    Gmesh.edges = {'points': np.unique(a, axis=0)}\n",
    "    ngbNbs, ngbID = definegtin(len(icoXYZ), Gmesh.cells('points'), Gmesh.edges['points'])\n",
    "    ngbIDs = ngbID[:,:8].astype(int)\n",
    "    return ngbIDs\n",
    "\n",
    "#Create an array of elevations\n",
    "def addElevationsToSphere(icosphere, \n",
    "                           octaves=8, \n",
    "                           octaveStepSize=1.5, \n",
    "                           amplitudeStepSize=2.4,\n",
    "                           initialFrequency=0.000001):\n",
    "    noiseMap = sampleNoise(icosphere.points, \n",
    "                           octaves=octaves, \n",
    "                           octaveStepSize=octaveStepSize, \n",
    "                           amplitudeStepSize=amplitudeStepSize,\n",
    "                           initialFrequency=initialFrequency)\n",
    "    icosphere['elevations'] = noiseMap * noiseAmplitude + noiseAmplitude * 0.3\n",
    "    return icosphere\n",
    "    \n",
    "def createInitialTopographyNPData(\n",
    "                                octaves=8,\n",
    "                                subdivisions=6,\n",
    "                                octaveStepSize=1.5, \n",
    "                                earthRadius=6378000,\n",
    "                                noiseAmplitude=10000,\n",
    "                                amplitudeStepSize=2.4,\n",
    "                                initialFrequency=0.000001,\n",
    "                                fileName = './Data/initLandscape.npz'):\n",
    "    \n",
    "    #Create an Icosphere and get it's vertices and cells\n",
    "    icosphere = createIcosphere(subdivisions=subdivisions, radius=earthRadius)\n",
    "    vertices = icosphere.points\n",
    "\n",
    "    #Get the cell array that we attached to the icosphere mesh object earlier on\n",
    "    cells = icosphere['cells']\n",
    "    \n",
    "    icosphere = addElevationsToSphere(icosphere)\n",
    "    elevations = icosphere['elevations']\n",
    "\n",
    "    #Create a list of neighbour ids\n",
    "    neighbs = getNeighbourIds(vertices, cells)\n",
    "    \n",
    "    #Save the file\n",
    "    np.savez_compressed(fileName, v=vertices, c=cells, n=neighbs.astype(int), z=elevations)\n",
    "    return icosphere\n",
    "    \n",
    "icosphere = createInitialTopographyNPData()\n",
    "\n",
    "#Plot the results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(icosphere, scalars='elevations')\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46ec0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of neighbour ids, based on bfModel notebook tutorial\n",
    "def getNeighbourIds(icoXYZ, icoCells):\n",
    "    Gmesh = meshplex.MeshTri(icoXYZ, icoCells)\n",
    "    s = Gmesh.idx_hierarchy.shape\n",
    "    a = np.sort(Gmesh.idx_hierarchy.reshape(s[0], -1).T)\n",
    "    Gmesh.edges = {'points': np.unique(a, axis=0)}\n",
    "    ngbNbs, ngbID = definegtin(len(icoXYZ), Gmesh.cells('points'), Gmesh.edges['points'])\n",
    "    ngbIDs = ngbID[:,:8].astype(int)\n",
    "    return ngbIDs\n",
    "\n",
    "#Create an Icosphere and get it's vertices and cells\n",
    "icosphere = createIcosphere(subdivisions=6, radius=earthRadius)\n",
    "vertices = icosphere.points\n",
    "\n",
    "#Get the cell array that we attached to the icosphere mesh object earlier on\n",
    "cells = icosphere['cells']\n",
    "\n",
    "icosphere = addElevationsToSphere(icosphere)\n",
    "elevations = icosphere['elevations']\n",
    "\n",
    "#Create a list of neighbour ids\n",
    "neighbs = getNeighbourIds(vertices, cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd35460e",
   "metadata": {},
   "source": [
    "# Generating Lots of Training Data\n",
    "\n",
    "In the code bellow, the function *runTrial()* will run a single gospl trial with the randomly generated input data above. The trials will be saved in a directory named *TrainingData*, and each trial will have their own *Tial{}* folder with some trial number. By running the *runTrial()* function multiple times, we will generate training data for our GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56aae542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create one set of training data by running gospl\n",
    "def runTrial(dataDir = './Data/TrainingData',\n",
    "            trialDirFormat = '{}/Trial{}',\n",
    "            npzDirFormat = '{}/NPZFiles',\n",
    "            initElevNPZformat = '{}/initElevations.npz',\n",
    "            ymlFileToCopy = 'NoiseSphereInput.yml'):\n",
    "    \n",
    "    #Make directory of training data if it does not already exist\n",
    "    if not os.path.isdir(dataDir):\n",
    "        os.mkdir(dataDir)\n",
    "\n",
    "    #Create a new subdirectories for each trial\n",
    "    trialNumber = 0\n",
    "    trialDir = trialDirFormat.format(dataDir, trialNumber)\n",
    "    while os.path.isdir(trialDir):\n",
    "        trialNumber += 1\n",
    "        trialDir = trialDirFormat.format(dataDir, trialNumber)\n",
    "    npzDir = npzDirFormat.format(trialDir)\n",
    "    initElevNPZ = initElevNPZformat.format(npzDir)\n",
    "    os.mkdir(trialDir)\n",
    "    os.mkdir(npzDir)\n",
    "    \n",
    "    #Create npz file if initial elevation\n",
    "    icosphere = createInitialTopographyNPData(fileName=initElevNPZ)\n",
    "    \n",
    "    #Read the YML file to copy\n",
    "    newYMLfileDir = trialDir + '/' + ymlFileToCopy\n",
    "    with open(ymlFileToCopy, 'r') as ymlFile:\n",
    "        ymlContent = ymlFile.read()\n",
    "        \n",
    "    #Fill in the missing blanks in the YML file and save it into the trial directory\n",
    "    ymlContent = ymlContent.format(trialDir, trialDir)\n",
    "    with open(newYMLfileDir, 'w') as newYMLfile:\n",
    "        newYMLfile.write(ymlContent)\n",
    "    \n",
    "    #Run simulation\n",
    "    mod = sim(newYMLfileDir, False, False)\n",
    "    mod.runProcesses()\n",
    "    mod.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8521d",
   "metadata": {},
   "source": [
    "Running the code bellow will generate training data until the user interupts. Since we will be needing lots of training data, we let this cell run overnight, and interupt it in the morning.\n",
    "\n",
    "Some data is provided in the Github. The provided data may be sufficient to run and debug code within this notebook, but it is not sufficient to effectively train any sort of machine learning network. On my local computer, I have run 360 different trials with the code bellow, which is about 40 Gb of data, too large to be included in the github.\n",
    "\n",
    "Note that on my computer, a single trial using the cell bellow takes about 112 seconds to run, thats 11.2 seconds per iteration to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be5fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while False:\n",
    "    runTrial()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde4247",
   "metadata": {},
   "source": [
    "# Reading and Visualizing Training Data\n",
    "\n",
    "Here we provide some functions for reading and visualizing the generated trainind data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Gospl file contains simulation output data at particular iterations during the simulation\n",
    "def readGosplFile(fileDir):\n",
    "    gosplDict = {}\n",
    "    with h5py.File(fileDir, \"r\") as f:\n",
    "        for key in f.keys():\n",
    "            gosplDict[key] = np.array(f[key])\n",
    "    return gosplDict\n",
    "\n",
    "#Create a sphere from the gospl output topography files\n",
    "def createSphereMesh(topoXYZ):\n",
    "    r, lon, lat = cartesianToPolarCoords(topoXYZ)\n",
    "    lonLatFlat = np.stack((lon, lat, np.zeros(lon.shape))).T\n",
    "    faces = pv.PolyData(lonLatFlat).delaunay_2d().faces\n",
    "    return pv.PolyData(topoXYZ, faces)\n",
    "\n",
    "#Exagerated mesh for plotting\n",
    "def createExageratedMesh(sphereMesh, keys, iteration=10, trialNumber=0):\n",
    "    dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(iteration)\n",
    "    data = readGosplFile(dataFile)\n",
    "    r, lon, lat = cartesianToPolarCoords(sphereMesh.points)\n",
    "    exegeratedRadius = earthRadius + 60 * data['elev']\n",
    "    sphereMesh.points =  polarToCartesian(exegeratedRadius[:, 0], lon, lat).T\n",
    "    for key in keys:\n",
    "        sphereMesh[key] = data[key]\n",
    "    return sphereMesh\n",
    "    \n",
    "    \n",
    "trialNumber = 0\n",
    "trialDataDirFormat = './Data/TrainingData/Trial{}/NoiseSphere/h5/'\n",
    "gosplKeys = ['elev', 'erodep', 'fillFA', 'flowAcc', 'rain', 'sedLoad']\n",
    "\n",
    "#Read topology file\n",
    "topologyFile = trialDataDirFormat.format(trialNumber) + 'topology.p0.h5'\n",
    "topoDict = readGosplFile(topologyFile)\n",
    "sphereXYZ = topoDict['coords']\n",
    "sphereMesh = createSphereMesh(sphereXYZ)\n",
    "\n",
    "#Read simulation data at iteration\n",
    "iteration = 10\n",
    "dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(iteration)\n",
    "dataDict = readGosplFile(dataFile)\n",
    "\n",
    "#Create a mesh of our randomly generated planet and plot results\n",
    "plotter = pv.PlotterITK()\n",
    "planetMesh = createExageratedMesh(sphereMesh, gosplKeys, iteration=iteration, trialNumber=trialNumber)\n",
    "plotter.add_mesh(planetMesh, scalars=dataDict['elev'])\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e86f5",
   "metadata": {},
   "source": [
    "The code bellow generates animations of our GOSPL simulation. Again, the resulting data is not too exciting, but it sufficient for prototyping different tensorflow neural networks.\n",
    "\n",
    "By default, the animation will be saved as an MP4 file in the same directory of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37171d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animateGosplResults(trialNumber, \n",
    "                        iterations=10, \n",
    "                        framesPerIteration=8, \n",
    "                        scalarToPlot='elev',\n",
    "                       animationDir='ErosionAnimation.mp4'):\n",
    "    \n",
    "    topologyFile = trialDataDirFormat.format(trialNumber) + 'topology.p0.h5'\n",
    "    topoDict = readGosplFile(topologyFile)\n",
    "    sphereXYZ = topoDict['coords']\n",
    "    sphereMesh = createSphereMesh(sphereXYZ)\n",
    "\n",
    "    #Create initial planet mesh\n",
    "    dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(0)\n",
    "    dataDict = readGosplFile(dataFile)\n",
    "    planetMesh = createExageratedMesh(sphereMesh, gosplKeys, iteration=0, trialNumber=trialNumber)\n",
    "\n",
    "    #Initiate the plotter for animation\n",
    "    plotter = pv.Plotter()\n",
    "    plannetActor = plotter.add_mesh(planetMesh, scalars=dataDict[scalarToPlot])\n",
    "    plotter.camera.zoom(1.4)\n",
    "    plotter.open_movie(animationDir)\n",
    "    for i in range(framesPerIteration):\n",
    "        plotter.write_frame()\n",
    "\n",
    "    #Loop through all iteration data files and draw animation frames\n",
    "    for i in range(iterations):\n",
    "        dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(i+1)\n",
    "        dataDict = readGosplFile(dataFile)\n",
    "        planetMesh = createExageratedMesh(sphereMesh, gosplKeys, iteration=i+1, trialNumber=trialNumber)\n",
    "        newScalars = dataDict[scalarToPlot]\n",
    "\n",
    "        #Draw animation frames\n",
    "        plotter.remove_actor(plannetActor)\n",
    "        plannetActor = plotter.add_mesh(planetMesh, scalars=dataDict[scalarToPlot])\n",
    "        for i in range(framesPerIteration):\n",
    "            plotter.write_frame()\n",
    "    plotter.close()\n",
    "\n",
    "animateGosplResults(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600e632",
   "metadata": {},
   "source": [
    "# Preprocess Data for Tensorflow\n",
    "\n",
    "Many machine learning libraries such as tensorflow have plenty of tools and algorithms built in to deal with image type data, so to keep things simple, we would like to convert our data set into an image representation. This will allow us to use convolutional layers in our neural network (NN), which tends to perform really well in images.\n",
    "\n",
    "Note that many of the novel NN based physics simulators use graph based methods, and generalize the convolutional layer into a general graph rather than restricting it on a 2D image format. Although this is the approach we might want to use in the future, these methods have only been around for a few years, and the tools for graph based methods are not as well established as compared to the usual image convolution layers. So to keep things simple for now, we will represent our data as images.\n",
    "\n",
    "To convert our data into image representations, we will interpolate our data into UV sphere. The lon/lat coordinates of vertices of a UV sphere can then be represented as the XY location that they fall into in the image, and parameters such as elevation and erosion deposition can be represented using the RGB channels of the image.\n",
    "\n",
    "The code bellow demonstrates how we can convert a UV sphere into a flat grid. Note that we will need to remove the vertices on the north/south poles to make this work. This grid can then be represented as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create UV sphere\n",
    "uvSphere = pv.Sphere()\n",
    "r, theta, phi = cartesianToPolarCoords(uvSphere.points)\n",
    "theta[theta<=0] += 360\n",
    "\n",
    "#Convert to flat point cloud\n",
    "zeros = np.zeros(theta.shape)\n",
    "XYZ = np.array([zeros, theta, phi]).T\n",
    "\n",
    "#Remove first two coordinates corresponding to north and south pole\n",
    "XYZ = XYZ[2:, :]\n",
    "lonLatPointCloud = pv.PolyData(XYZ)\n",
    "pointCloudGlyphs = lonLatPointCloud.glyph(geom=pv.Sphere(radius=1))\n",
    "\n",
    "#Color to plot our points with\n",
    "colors = np.arange(pointCloudGlyphs.points.shape[0])\n",
    "\n",
    "#Plot results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(pointCloudGlyphs, scalars=colors)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157bdeb",
   "metadata": {},
   "source": [
    "We now need to interpolate our data onto a UV sphere. To do so, we will need the lon/lat coordinates of the Icosphere to interpolate from, the lon/lat coordinates of the UV sphere to interpolate onto, and the data to interpolate. We can then use the griddata interpolator form the scipy library.\n",
    "\n",
    "Note that since images have 3 color channels (RGB), we can use 3 scalar values produced by Gospl in the image. This will give more data for our NN to work with. In the code bellow, we interpolate elevation, erosion deposition and flow accumulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd47d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create lon/lat from gospl's icosphere to interpolate from\n",
    "def getIcoLonLat(trialNumber=0):\n",
    "    topologyFile = trialDataDirFormat.format(trialNumber) + 'topology.p0.h5'\n",
    "    topoDict = readGosplFile(topologyFile)\n",
    "    icoSphereXYZ = topoDict['coords']\n",
    "    icoSphereMesh = createSphereMesh(icoSphereXYZ)\n",
    "    _, icoLon, icoLat = cartesianToPolarCoords(icoSphereXYZ)\n",
    "    icoLon[icoLon<=0] += 360\n",
    "    return np.array([icoLon, icoLat]).T\n",
    "\n",
    "#Create lon/lat to interpolate onto\n",
    "def getUVLonLat(resolution=[512, 258]):\n",
    "    uvSphere = pv.Sphere(theta_resolution=resolution[0], phi_resolution=resolution[1])\n",
    "    _, uvLon, uvLat = cartesianToPolarCoords(uvSphere.points)\n",
    "    uvLon[uvLon<=0] += 360\n",
    "    return np.array([uvLon, uvLat]).T\n",
    "\n",
    "#Use griddata interpolation to get scalars of the UV sphere\n",
    "def getInterpolatedData(trialNumber, iteration, icoLonLat, uvLonLat,\n",
    "                        scalarsToInterpolate=['elev', 'erodep', 'flowAcc']):\n",
    "    \n",
    "    #Get data to interpolate\n",
    "    dataFile = trialDataDirFormat.format(trialNumber) + 'gospl.{}.p0.h5'.format(iteration)\n",
    "    dataDict = readGosplFile(dataFile)\n",
    "    interpolatedScalars = []\n",
    "    \n",
    "    #Loop through all scalars to interpolate\n",
    "    for scalar in scalarsToInterpolate:\n",
    "        newScalar = griddata(icoLonLat, dataDict[scalar], uvLonLat)\n",
    "        whereNAN = np.argwhere(np.isnan(newScalar))\n",
    "        newScalar[whereNAN] = griddata(icoLonLat, dataDict[scalar], uvLonLat[whereNAN], method='nearest')\n",
    "        interpolatedScalars.append(newScalar)\n",
    "    return np.array(interpolatedScalars).T[0]\n",
    "\n",
    "trialNumber = 1\n",
    "iteration = 10\n",
    "\n",
    "#Get interpolated data for the UV sphere\n",
    "uvLonLat = getUVLonLat()\n",
    "icoLonLat = getIcoLonLat()\n",
    "interpolatedData = getInterpolatedData(trialNumber, iteration, icoLonLat, uvLonLat)\n",
    "\n",
    "#Plot results\n",
    "plotter = pv.PlotterITK()\n",
    "uvSphere = pv.Sphere(theta_resolution=512, phi_resolution=258)\n",
    "plotter.add_mesh(uvSphere, scalars=interpolatedData[:, 0])\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae586ae",
   "metadata": {},
   "source": [
    "Now that we have the data interpolated onto a UV sphere, we can represent it by an image. First we reshape the data array into an image shape, and then bring all values to a range from 0 to 255 as required for 8 bit pixels. We also raise the flow accumulation variable by the power of 0.125, to make it's distribution more linear and therefore more visible.\n",
    "\n",
    "Note: I've recently made the relization that I could probably save the data as NPZ files and avoid loss of fidelity due to saving as PNG and the 8 Bit restriction. The data still needs to be represented in a flat 2D image like grid of values though, but I'm not restricted to 3 RGB channels either. We will keep the code here as it is, however in the next attempt we will be saving all our training data as NPZ files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4dc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The interpolated data is save in the RGB channels of the image\n",
    "#We bring data into range from 0 to 255, as required for images\n",
    "def createImage(rgb):\n",
    "    RGB = np.copy(rgb)\n",
    "    RGB = RGB[2:].reshape(512, 256, 3)\n",
    "    RGB[:, :, 2] = RGB[:, :, 2]**0.125\n",
    "    RGB -= np.min(interpolatedData, axis=0)\n",
    "    RGB[:, :, 0] /= np.max(RGB[:, :, 0])\n",
    "    RGB[:, :, 2] /= np.max(RGB[:, :, 2])\n",
    "    if np.max(RGB[:, :, 1]) != 0:\n",
    "        RGB[:, :, 1] /= np.max(RGB[:, :, 1])\n",
    "    RGB *= 255\n",
    "    return Image.fromarray(RGB.astype(np.uint8))\n",
    "\n",
    "trialNumber = 1\n",
    "iteration = 10\n",
    "\n",
    "#Get data to be represented by images\n",
    "uvLonLat = getUVLonLat()\n",
    "icoLonLat = getIcoLonLat()\n",
    "interpolatedData = getInterpolatedData(trialNumber, iteration, icoLonLat, uvLonLat)\n",
    "\n",
    "#Display or save image\n",
    "img = createImage(interpolatedData)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261795e9",
   "metadata": {},
   "source": [
    "We probably also want to make sure we can read images back into a spherical mesh format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthRadius = 6378000\n",
    "rangeMax = np.array([9.21434829e+03, 5.20667833e+03, 3.23146528e+14])\n",
    "rangeMin = np.array([-9.62599721e+02, -1.49130044e+03,  1.00000000e+00])\n",
    "\n",
    "#Read image for heights data\n",
    "image = Image.open(\"testImage.png\")\n",
    "dataArray = np.array(image)\n",
    "heights = dataArray[:, :,0]\n",
    "heights = heights * (rangeMax[0] - rangeMin[0]) / 255 + rangeMin[0]\n",
    "\n",
    "#Insert back the north and south pole, for now we just let it be zero, but we can interpolate to get a better value\n",
    "heights = np.insert(heights, 0, 0)\n",
    "heights = np.insert(heights, 0, 0)\n",
    "\n",
    "#Apply the noise radius to our sphere\n",
    "uvSphere = pv.Sphere(radius=earthRadius, theta_resolution=512, phi_resolution=258)\n",
    "r, lon, lat = cartesianToPolarCoords(np.array(uvSphere.points))\n",
    "noisySphereXYZ = polarToCartesian(heights * 60 + earthRadius, lon, lat)\n",
    "noisySphere = pv.PolyData(noisySphereXYZ, uvSphere.faces)\n",
    "\n",
    "#Plot results\n",
    "plotter = pv.PlotterITK()\n",
    "plotter.add_mesh(noisySphere, scalars=heights)\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebfd3c1",
   "metadata": {},
   "source": [
    "Now that we have a way of representing our data as images, we wan't to convert all our data files into images for tensorflow. For each feature (input data), we want the target (output of NN) to be the next iteration of the GOSPL simulation. So each iteration will be an feature with the next iteration as the target data.\n",
    "\n",
    "In machine learning literature, a feature is the input of a model, and the target is the output of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a803260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialNumber = 25\n",
    "iteration = 10\n",
    "\n",
    "#Get data to be represented by images\n",
    "uvLonLat = getUVLonLat()\n",
    "icoLonLat = getIcoLonLat()\n",
    "\n",
    "#Loop through all images and save feature/target image pairs\n",
    "count = 0\n",
    "if False:\n",
    "    for trial in range(2):\n",
    "        for i in range(iteration):\n",
    "            featureData = getInterpolatedData(trial, i, icoLonLat, uvLonLat)\n",
    "            featureImage = createImage(featureData)\n",
    "            featureImage.save('./Data/ImageTrainingData/Features/feature{}.png'.format(count))\n",
    "\n",
    "            targetData = getInterpolatedData(trial, i+1, icoLonLat, uvLonLat)\n",
    "            targetImage = createImage(targetData)\n",
    "            targetImage.save('./Data/ImageTrainingData/Targets/target{}.png'.format(count))\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a7acb",
   "metadata": {},
   "source": [
    "# Next Notebook\n",
    "\n",
    "We have succesfully used GOSPL to generate training data for our neural network. In the next notebook, we will explore various tensorflow models (GAN) and test out which ones perform the best.\n",
    "\n",
    "To run the next notebook, make sure your python environment has access to tensorflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
